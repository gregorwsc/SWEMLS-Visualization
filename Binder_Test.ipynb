{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "\n",
    "def show_exception(e):\n",
    "    print(\"‚ùå Exception caught:\")\n",
    "    traceback.print_exception(type(e), e, e.__traceback__, file=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rdflib import Graph, Namespace\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "\n",
    "shacl_output = widgets.Output()\n",
    "\n",
    "# === SHACL-Regeln anwenden auf hochgeladene Datei ===\n",
    "def apply_shacl_rules(instance_file_path: str) -> Graph:\n",
    "    SH = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    shapes_dir = \"Shapes\"  # relative Pfadangabe im Repo\n",
    "\n",
    "    shape_files = [\n",
    "        \"_generic-shapes.ttl\", \"A1-shapes.ttl\", \"A2-shapes.ttl\", \"A3-shapes.ttl\",\n",
    "        \"F1-shapes.ttl\", \"F2-shapes.ttl\", \"F3-shapes.ttl\", \"F4-shapes.ttl\",\n",
    "        \"I1-shapes.ttl\", \"I2-shapes.ttl\", \"I3-shapes.ttl\", \"I4-shapes.ttl\",\n",
    "        \"I5-shapes.ttl\", \"I6-shapes.ttl\", \"I7-shapes.ttl\", \"O1-shapes.ttl\",\n",
    "        \"O2-shapes.ttl\", \"O3-shapes.ttl\", \"O4-shapes.ttl\", \"T1-shapes.ttl\",\n",
    "        \"T2-shapes.ttl\", \"T3-shapes.ttl\", \"T4-shapes.ttl\", \"T5-shapes.ttl\",\n",
    "        \"T6-shapes.ttl\", \"T7-shapes.ttl\", \"T8-shapes.ttl\", \"T9-shapes.ttl\",\n",
    "        \"T10-shapes.ttl\", \"T11-shapes.ttl\", \"T12-shapes.ttl\", \"T13-shapes.ttl\",\n",
    "        \"T14-shapes.ttl\", \"T15-shapes.ttl\", \"T16-shapes.ttl\", \"T17-shapes.ttl\",\n",
    "        \"T18-shapes.ttl\", \"T19-shapes.ttl\", \"T20-shapes.ttl\", \"T21-shapes.ttl\",\n",
    "        \"T22-shapes.ttl\", \"T23-shapes.ttl\", \"Y1-shapes.ttl\", \"Y2-shapes.ttl\", \"Y4-shapes.ttl\"\n",
    "    ]\n",
    "\n",
    "    g_instance = Graph()\n",
    "    g_instance.parse(instance_file_path, format=\"turtle\")\n",
    "\n",
    "    triples_before = len(g_instance)\n",
    "\n",
    "    for shape_file in shape_files:\n",
    "        shape_path = os.path.join(shapes_dir, shape_file)\n",
    "        g_shape = Graph()\n",
    "\n",
    "        if not os.path.exists(shape_path):\n",
    "            with shacl_output:\n",
    "                print(f\"‚ö†Ô∏è Shape file not found: {shape_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            g_shape.parse(shape_path, format=\"turtle\")\n",
    "            with shacl_output:\n",
    "                print(f\"‚úÖ Loaded SHACL shape file: {shape_file}\")\n",
    "        except Exception as e:\n",
    "            with shacl_output:\n",
    "                print(f\"‚ùå Error loading {shape_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for rule in g_shape.subjects(predicate=SH.rule, object=None):\n",
    "            for _, _, construct_query in g_shape.triples((rule, SH.construct, None)):\n",
    "                query = str(construct_query)\n",
    "                try:\n",
    "                    g_instance.update(query)\n",
    "                except Exception as e:\n",
    "                    with shacl_output:\n",
    "                        print(f\"‚ùå Error executing rule from {shape_file}: {e}\")\n",
    "\n",
    "    triples_after = len(g_instance)\n",
    "    with shacl_output:\n",
    "        print(\"‚úÖ All rules applied.\")\n",
    "        print(f\"üìä Triples before: {triples_before}\")\n",
    "        print(f\"üìà Triples after: {triples_after}\")\n",
    "        print(f\"‚ûï Added: {triples_after - triples_before} triples\")\n",
    "\n",
    "    return g_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from rdflib import Graph\n",
    "\n",
    "# === Globale Variablen ===\n",
    "instance_file_path = None\n",
    "output = widgets.Output()\n",
    "result_graph = None\n",
    "\n",
    "\n",
    "\n",
    "# === Auswahlfeld: Beispiel oder Upload ===\n",
    "option_selector = widgets.ToggleButtons(\n",
    "    options=[(\"Use example file\", \"example\"), (\"Upload your own\", \"upload\")],\n",
    "    description=\"Select input:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# === Upload-Widget (immer sichtbar) ===\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload TTL file'\n",
    ")\n",
    "\n",
    "# === \"Continue\"-Button ===\n",
    "continue_button = widgets.Button(description=\"Continue\", button_style='primary')\n",
    "\n",
    "# === Auswahlhandler ===\n",
    "def on_option_change(change):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        if change['new'] == 'example':\n",
    "            global instance_file_path\n",
    "            instance_file_path = \"Instance_Files/swemls-instances.ttl\"\n",
    "            print(f\"üìÅ Example file selected:\\n‚Üí {instance_file_path}\")\n",
    "        elif change['new'] == 'upload':\n",
    "            print(\"üì§ Please upload a TTL file using the field below.\")\n",
    "\n",
    "option_selector.observe(on_option_change, names='value')\n",
    "\n",
    "# === Upload-Handler ===\n",
    "def on_upload(change):\n",
    "    global instance_file_path\n",
    "    if upload_widget.value:\n",
    "        uploaded = upload_widget.value[0]\n",
    "        file_name = uploaded['name']\n",
    "        instance_file_path = file_name\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(uploaded['content'])\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(f\"‚úÖ File uploaded and saved as:\\n‚Üí {file_name}\")\n",
    "\n",
    "upload_widget.observe(on_upload, names='value')\n",
    "\n",
    "# === Continue-Button-Handler ===\n",
    "def on_continue(b):\n",
    "    global result_graph\n",
    "    output.clear_output()\n",
    "    if not instance_file_path:\n",
    "        with output:\n",
    "            print(\"‚ö†Ô∏è No file selected or uploaded.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(instance_file_path):\n",
    "        with output:\n",
    "            print(f\"‚ùå File not found on disk:\\n‚Üí {instance_file_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if instance_file_path.endswith(\".ttl\") and not instance_file_path.startswith(\"Instance_Files/\"):\n",
    "            with output:\n",
    "                print(\"üîç SHACL rules will be applied to uploaded file.\")\n",
    "            result_graph = apply_shacl_rules(instance_file_path)\n",
    "        else:\n",
    "            g = Graph()\n",
    "            g.parse(instance_file_path, format=\"turtle\")\n",
    "            result_graph = g\n",
    "\n",
    "        with output:\n",
    "            print(f\"‚úÖ RDF file successfully loaded!\")\n",
    "            print(f\"üìÑ Triples in graph: {len(result_graph)}\")\n",
    "            print(f\"üîó Using file:\\n‚Üí {instance_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"‚ùå Error parsing TTL file:\\n‚Üí {e}\")\n",
    "\n",
    "    # ‚¨áÔ∏è SHACL-Ausgabe sichtbar machen\n",
    "    display(shacl_output)\n",
    "\n",
    "continue_button.on_click(on_continue)\n",
    "\n",
    "# === Anzeige aller Elemente ===\n",
    "display(option_selector, upload_widget, continue_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from rdflib.namespace import RDF\n",
    "from IPython.display import display\n",
    "\n",
    "# Outputs\n",
    "query_interface_output = widgets.Output()\n",
    "selection_output = widgets.Output()\n",
    "\n",
    "# SPARQL Query-Feld\n",
    "query_input = widgets.Textarea(\n",
    "    value=\"\"\"\n",
    "PREFIX swemls: <https://w3id.org/semsys/ns/swemls#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?system\n",
    "WHERE {\n",
    "  ?system a swemls:System .\n",
    "  ?system swemls:hasCorrespondingPattern ?pattern .\n",
    "  FILTER(STRENDS(STR(?pattern), \"O1\"))\n",
    "}\n",
    "\"\"\",\n",
    "    placeholder='Enter your SPARQL query here...',\n",
    "    description='SPARQL Query:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Buttons\n",
    "run_query_button = widgets.Button(description=\"Run Query\", button_style='primary')\n",
    "confirm_button = widgets.Button(description=\"Confirm selection\", button_style='success')\n",
    "\n",
    "# Dropdown f√ºr Systeme\n",
    "system_selector = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description=\"Select system:\",\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Globales Ergebnis\n",
    "matched_systems = []\n",
    "\n",
    "# Query-Handler\n",
    "def on_query_run(b):\n",
    "    global matched_systems\n",
    "    query_interface_output.clear_output()\n",
    "    selection_output.clear_output()\n",
    "    system_selector.options = []\n",
    "\n",
    "    if 'result_graph' not in globals() or result_graph is None:\n",
    "        with query_interface_output:\n",
    "            print(\"‚ö†Ô∏è RDF graph not loaded.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        results = result_graph.query(query_input.value)\n",
    "    except Exception as e:\n",
    "        with query_interface_output:\n",
    "            print(f\"‚ùå Query error: {e}\")\n",
    "        return\n",
    "\n",
    "    matched_systems = []\n",
    "    for row in results:\n",
    "        uri = str(row.system)\n",
    "        sys_id = uri.split(\"/\")[-1]\n",
    "        matched_systems.append((sys_id, uri))\n",
    "\n",
    "    if not matched_systems:\n",
    "        with query_interface_output:\n",
    "            print(\"‚ö†Ô∏è No matching systems found.\")\n",
    "        return\n",
    "\n",
    "    system_selector.options = [(sys_id, uri) for sys_id, uri in matched_systems]\n",
    "\n",
    "    with query_interface_output:\n",
    "        print(f\"‚úÖ Found {len(matched_systems)} matching system(s):\")\n",
    "        for i, (sys_id, _) in enumerate(matched_systems):\n",
    "            print(f\" {i+1}: {sys_id}\")\n",
    "\n",
    "# Auswahl-Handler\n",
    "def on_confirm_selection(b):\n",
    "    global selected_system_id, selected_system_uri\n",
    "    selected_label = system_selector.label\n",
    "    selected_uri = system_selector.value\n",
    "    selected_system_id = selected_label\n",
    "    selected_system_uri = selected_uri\n",
    "    with selection_output:\n",
    "        selection_output.clear_output()\n",
    "        print(f\"‚úÖ You selected: {selected_system_id}\")\n",
    "        print(f\"üîó URI: {selected_system_uri}\")\n",
    "\n",
    "# Event-Bindings\n",
    "run_query_button.on_click(on_query_run)\n",
    "confirm_button.on_click(on_confirm_selection)\n",
    "\n",
    "# Anzeigen\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        query_input,\n",
    "        run_query_button,\n",
    "        query_interface_output,\n",
    "        widgets.HBox([system_selector, confirm_button]),\n",
    "        selection_output\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "json_output = widgets.Output()\n",
    "\n",
    "def extract_and_export_selected_system():\n",
    "    global selected_system_id, selected_system_uri, result_graph\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology#\")\n",
    "    RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "    rdf_type = URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\")\n",
    "    ai_system_type = SWEMLS.System\n",
    "    documentation_type = SWEMLS.Documentation\n",
    "    paper_type = SWEMLS.Paper\n",
    "    ml_component_type = SWEMLS.MachineLearningComponent\n",
    "    kr_component_type = SWEMLS.KnowledgeRepresentationComponent\n",
    "    data_type = SWEMLS.Data\n",
    "    semantic_web_resource_type = SWEMLS.SemanticWebResource\n",
    "    has_documentation = SWEMLS.hasDocumentation\n",
    "    reports_on = SWEMLS.reports\n",
    "    rdfs_label = RDFS.label\n",
    "\n",
    "    g = result_graph\n",
    "\n",
    "    # 1. System und zugeh√∂rige Paper finden\n",
    "    ai_systems = [\n",
    "        system for system in g.subjects(RDF.type, ai_system_type)\n",
    "        if str(system).split(\"/\")[-1] == selected_system_id\n",
    "    ]\n",
    "\n",
    "    system_to_paper = {}\n",
    "    for paper in g.subjects(predicate=rdf_type, object=paper_type):\n",
    "        for reported_system in g.objects(subject=paper, predicate=reports_on):\n",
    "            system_id = str(reported_system).split(\"/\")[-1]\n",
    "            paper_id = str(paper).split(\"/\")[-1]\n",
    "            paper_metadata = {\"id\": paper_id, \"metadata\": {}}\n",
    "            for pred, obj in g.predicate_objects(subject=paper):\n",
    "                pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "                paper_metadata[\"metadata\"].setdefault(pred_name, []).append(str(obj))\n",
    "            system_to_paper.setdefault(system_id, []).append(paper_metadata)\n",
    "\n",
    "    # 2. System extrahieren\n",
    "    for system in ai_systems:\n",
    "        instance_data = {\n",
    "            \"id\": str(system).split(\"/\")[-1],\n",
    "            \"type\": \"System\",\n",
    "            \"metadata\": {},\n",
    "            \"relationships\": {},\n",
    "            \"documentation\": {},\n",
    "            \"papers\": [],\n",
    "            \"steps\": [],\n",
    "            \"variables\": {}\n",
    "        }\n",
    "\n",
    "        for pred, obj in g.predicate_objects(subject=system):\n",
    "            pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "            if isinstance(obj, URIRef):\n",
    "                instance_data[\"relationships\"].setdefault(pred_name, []).append(str(obj).split(\"/\")[-1])\n",
    "            else:\n",
    "                instance_data[\"metadata\"][pred_name] = str(obj)\n",
    "\n",
    "        # 3. Dokumentation extrahieren\n",
    "        if \"hasDocumentation\" in instance_data[\"relationships\"]:\n",
    "            for doc_id in instance_data[\"relationships\"][\"hasDocumentation\"]:\n",
    "                doc_uri = URIRef(f\"http://semantic-systems.net/swemls/{doc_id}\")\n",
    "                if (doc_uri, rdf_type, documentation_type) in g:\n",
    "                    instance_data[\"documentation\"][\"id\"] = doc_id\n",
    "                    for doc_pred, doc_obj in g.predicate_objects(subject=doc_uri):\n",
    "                        doc_pred_name = doc_pred.split(\"#\")[-1] if \"#\" in doc_pred else doc_pred.split(\"/\")[-1]\n",
    "                        instance_data[\"documentation\"][doc_pred_name] = str(doc_obj)\n",
    "\n",
    "        # 4. Paper hinzuf√ºgen\n",
    "        if selected_system_id in system_to_paper:\n",
    "            instance_data[\"papers\"] = system_to_paper[selected_system_id]\n",
    "\n",
    "        # 5. Schritte (ML/KR) extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for step_relation in [f\"hasStepML{i}\", f\"hasStepKR{i}\"]:\n",
    "                if step_relation in instance_data[\"relationships\"]:\n",
    "                    for step_id in instance_data[\"relationships\"][step_relation]:\n",
    "                        step_uri = URIRef(f\"http://semantic-systems.net/swemls/{step_id}\")\n",
    "                        step_type = \"Unknown\"\n",
    "                        if (step_uri, rdf_type, ml_component_type) in g:\n",
    "                            step_type = \"Machine Learning\"\n",
    "                        elif (step_uri, rdf_type, kr_component_type) in g:\n",
    "                            step_type = \"Knowledge Representation\"\n",
    "                        step_data = {\"id\": step_id, \"type\": step_type, \"metadata\": {}}\n",
    "                        for step_pred, step_obj in g.predicate_objects(subject=step_uri):\n",
    "                            step_pred_name = step_pred.split(\"#\")[-1] if \"#\" in step_pred else step_pred.split(\"/\")[-1]\n",
    "                            step_data[\"metadata\"].setdefault(step_pred_name, []).append(str(step_obj))\n",
    "                        instance_data[\"steps\"].append(step_data)\n",
    "\n",
    "        # 6. Variablen extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for var_relation in [f\"hasVariableData{i}\", f\"hasVariableSW{i}\"]:\n",
    "                if var_relation in instance_data[\"relationships\"]:\n",
    "                    for var_id in instance_data[\"relationships\"][var_relation]:\n",
    "                        var_uri = URIRef(f\"http://semantic-systems.net/swemls/{var_id}\")\n",
    "                        label = None\n",
    "                        for _, _, label_value in g.triples((var_uri, rdfs_label, None)):\n",
    "                            label = str(label_value)\n",
    "                            break\n",
    "                        instance_data[\"variables\"][var_relation] = {\"id\": var_id, \"label\": label}\n",
    "\n",
    "        # 7. Speichern\n",
    "        json_filename = f\"{selected_system_id}.json\"\n",
    "        with open(json_filename, \"w\") as f:\n",
    "            json.dump(instance_data, f, indent=4)\n",
    "\n",
    "        with json_output:\n",
    "            json_output.clear_output()\n",
    "            print(f\"‚úÖ JSON successfully exported as: {json_filename}\")\n",
    "            print(json.dumps(instance_data, indent=2))  # Ausgabe f√ºr √úberpr√ºfung\n",
    "\n",
    "# === Button zum Starten der Extraktion ===\n",
    "extract_button = widgets.Button(description=\"Extract JSON\", button_style=\"success\")\n",
    "extract_button.on_click(lambda b: extract_and_export_selected_system())\n",
    "\n",
    "display(extract_button, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "pattern_output = widgets.Output()\n",
    "\n",
    "# === Component Mapping f√ºr automatische Generierung oder Pattern-Upload ===\n",
    "import re\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def run_component_mapping():\n",
    "    global components, json_to_pattern_map, edges\n",
    "\n",
    "    display(\"üß© Starte Component Mapping ...\")\n",
    "\n",
    "    # Schritt 1: Mapping von JSON zu Pattern-K√ºrzeln (Verwendung der ID anstelle des Labels)\n",
    "    json_to_pattern_map = {}\n",
    "\n",
    "    for step in instance_data[\"steps\"]:\n",
    "        step_key = step[\"id\"].split(\".\")[-1]  # Extrahiere die ID des Schrittes\n",
    "        json_to_pattern_map[step_key] = step[\"id\"]  # Speichere die ID statt des Labels\n",
    "\n",
    "    for var_key, var_data in instance_data[\"variables\"].items():\n",
    "        json_to_pattern_map[var_key] = var_data[\"id\"]  # Verwende die ID der Variablen\n",
    "\n",
    "    for var_data in instance_data[\"variables\"].values():\n",
    "        key = var_data[\"id\"].split(\".\")[-1]\n",
    "        if key not in json_to_pattern_map:\n",
    "            json_to_pattern_map[key] = var_data[\"id\"]\n",
    "\n",
    "    # Schritt 2: Komponentenstruktur initialisieren\n",
    "    components = {\n",
    "        \"ml_component\": [],\n",
    "        \"kr_component\": [],\n",
    "        \"data\": [],\n",
    "        \"symbolic_data\": []\n",
    "    }\n",
    "\n",
    "    for step in instance_data[\"steps\"]:\n",
    "        step_type_list = step.get(\"metadata\", {}).get(\"type\", [])\n",
    "        step_type = step_type_list[-1] if step_type_list else \"\"\n",
    "        if \"MachineLearningComponent\" in step_type and step[\"id\"] not in components[\"ml_component\"]:\n",
    "            components[\"ml_component\"].append(step[\"id\"])\n",
    "        elif \"KnowledgeRepresentationComponent\" in step_type and step[\"id\"] not in components[\"kr_component\"]:\n",
    "            components[\"kr_component\"].append(step[\"id\"])\n",
    "\n",
    "    for var_relation, var_data in instance_data[\"variables\"].items():\n",
    "        if \"SW\" in var_relation:\n",
    "            components[\"symbolic_data\"].append(var_data[\"id\"])\n",
    "        else:\n",
    "            components[\"data\"].append(var_data[\"id\"])\n",
    "\n",
    "    # Schritt 3: Fehlende Variablen im Pattern erg√§nzen\n",
    "    for key in set(json_to_pattern_map.keys()) - set(pattern_structure[\"variables\"].keys()):\n",
    "        pattern_structure[\"variables\"][key] = {\"generated_by\": []}\n",
    "\n",
    "    # Schritt 4: Letzter Check auf fehlende Nodes\n",
    "    missing_nodes = set(json_to_pattern_map.keys()) - set(pattern_structure[\"variables\"].keys()) - set(pattern_structure[\"steps\"].keys())\n",
    "    if missing_nodes:\n",
    "        display(f\" ‚ö†Ô∏è WARNING: Nodes still missing after fix: {missing_nodes}\")\n",
    "\n",
    "    # === Edge Mapping ===\n",
    "    display(\"\\nüîó Starte Edge Mapping...\")\n",
    "\n",
    "    edges = []  # Initialize edges list\n",
    "\n",
    "    # Dynamische Zuordnung spezieller Variablen\n",
    "    special_mappings = {f\"Data{i}\": f\"hasVariableData{i}\" for i in range(1, 11)}\n",
    "    special_mappings.update({f\"SW{i}\": f\"hasVariableSW{i}\" for i in range(1, 11)})\n",
    "\n",
    "    # Fehlende Pattern-Variablen erg√§nzen\n",
    "    for var_name in pattern_structure[\"variables\"]:\n",
    "        if var_name not in json_to_pattern_map:\n",
    "            found_match = False\n",
    "\n",
    "            if var_name in special_mappings:\n",
    "                mapped_var = instance_data[\"variables\"].get(special_mappings[var_name], {}).get(\"id\")\n",
    "                if mapped_var:\n",
    "                    json_to_pattern_map[var_name] = mapped_var\n",
    "                    found_match = True\n",
    "\n",
    "            if not found_match:\n",
    "                for var_key, var_data in instance_data[\"variables\"].items():\n",
    "                    if var_name.lower() in var_key.lower():\n",
    "                        json_to_pattern_map[var_name] = var_data[\"id\"]\n",
    "                        found_match = True\n",
    "                        break\n",
    "\n",
    "            if not found_match:\n",
    "                for rel_key, rel_values in instance_data[\"relationships\"].items():\n",
    "                    if isinstance(rel_values, list):\n",
    "                        for value in rel_values:\n",
    "                            if var_name.lower() == value.split(\".\")[-1].lower():\n",
    "                                json_to_pattern_map[var_name] = value\n",
    "                                found_match = True\n",
    "                                break\n",
    "                    if found_match:\n",
    "                        break\n",
    "\n",
    "            if not found_match:\n",
    "                json_to_pattern_map[var_name] = var_name\n",
    "\n",
    "    # Kanten generieren (Hier wird sichergestellt, dass alle echten IDs verwendet werden)\n",
    "    for step, relations in pattern_structure[\"steps\"].items():\n",
    "        step_real_id = json_to_pattern_map.get(step, step)\n",
    "\n",
    "        # \"used\"-Kanten erstellen\n",
    "        for used in relations.get(\"uses\", []):\n",
    "            used_real_id = json_to_pattern_map.get(used, used)\n",
    "            if used_real_id and step_real_id:\n",
    "                edges.append((used_real_id, step_real_id))\n",
    "\n",
    "        # \"output\"-Kanten erstellen\n",
    "        for output in relations.get(\"outputs\", []):\n",
    "            output_real_id = json_to_pattern_map.get(output, output)\n",
    "            if output_real_id and step_real_id:\n",
    "                edges.append((step_real_id, output_real_id))\n",
    "\n",
    "    display(f\"\\n‚úÖ Final Edge List: {edges}\")\n",
    "\n",
    "    # Pr√ºfen auf unverbundene Knoten\n",
    "    all_edge_nodes = {node for edge in edges for node in edge}\n",
    "    unlinked_nodes = set(json_to_pattern_map.values()) - all_edge_nodes\n",
    "    if unlinked_nodes:\n",
    "        display(f\"‚ö†Ô∏è WARNING: Nodes in mapping but not used in edges: {unlinked_nodes}\")\n",
    "\n",
    "    # Ausgabe der components-Struktur\n",
    "    display(\"\\nüß© Components Struktur:\")\n",
    "    display(components)\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "def assign_ranks_with_limited_correction(components, edges):\n",
    "    print(\"üîß Starte Topological Rank Assignment mit begrenzter Korrektur (nur bei Knoten ohne Vorg√§nger)...\\n\")\n",
    "\n",
    "    # Schritt 1: Graph konstruieren\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    if not nx.is_directed_acyclic_graph(G):\n",
    "        print(\"‚ùå Fehler: Der Graph enth√§lt einen Zyklus.\")\n",
    "        return None\n",
    "\n",
    "    topo_order = list(nx.topological_sort(G))\n",
    "\n",
    "    # Schritt 2: Initiale Rangzuweisung\n",
    "    rank_map = {}\n",
    "    for node in topo_order:\n",
    "        preds = list(G.predecessors(node))\n",
    "\n",
    "        if not preds:\n",
    "            rank_map[node] = 0\n",
    "        else:\n",
    "            rank_map[node] = max(rank_map[p] + 1 for p in preds)\n",
    "\n",
    "    print(\"üéØ Vorl√§ufige R√§nge:\")\n",
    "    for node, rank in rank_map.items():\n",
    "        print(f\"  {node}: Rang {rank}\")\n",
    "\n",
    "    # Schritt 3: Korrektur nur f√ºr Knoten ohne Vorg√§nger\n",
    "    print(\"\\nüîÅ Starte begrenzte Shared-Input-Korrektur f√ºr Knoten ohne Vorg√§nger...\")\n",
    "    \n",
    "    all_targets = defaultdict(list)\n",
    "    for source, target in edges:\n",
    "        all_targets[source].append(target)\n",
    "\n",
    "    for node, targets in all_targets.items():\n",
    "        if list(G.predecessors(node)):  # Skip nodes with predecessors\n",
    "            continue\n",
    "\n",
    "        candidate_ranks = []\n",
    "        for target in targets:\n",
    "            target_rank = rank_map.get(target, 1)\n",
    "            candidate_ranks.append(target_rank - 1)\n",
    "\n",
    "        if candidate_ranks:\n",
    "            new_rank = min(candidate_ranks)\n",
    "            if new_rank >= 0 and new_rank != rank_map[node]:\n",
    "                print(f\"  üîÅ Korrektur: {node} von Rang {rank_map[node]} ‚Üí {new_rank} (basierend auf {len(candidate_ranks)} Targets)\")\n",
    "                rank_map[node] = new_rank\n",
    "\n",
    "    # Schritt 4: Gruppierung nach R√§ngen\n",
    "    grouped = defaultdict(list)\n",
    "    for node, rank in rank_map.items():\n",
    "        grouped[rank].append(node)\n",
    "\n",
    "    print(\"\\nüìä Final zugewiesene R√§nge nach Korrektur:\")\n",
    "    for rank in sorted(grouped):\n",
    "        print(f\"  Rang {rank}: {grouped[rank]}\")\n",
    "\n",
    "    return rank_map\n",
    "\n",
    "\n",
    "# ‚úÖ Funktion zur Anwendung des Positionsalgorithmus f√ºr die F√§lle ohne Template-Auswahl\n",
    "def apply_positioning_algorithm():\n",
    "    # Zun√§chst sicherstellen, dass Component Mapping und Edge Mapping abgeschlossen sind\n",
    "    if components and edges:\n",
    "        print(\"üîß Rangzuweisung f√ºr das Workflow XML starten...\")\n",
    "        rank_map = assign_ranks_with_limited_correction(components, edges)\n",
    "        \n",
    "        if rank_map:\n",
    "            print(\"\\n‚úÖ Rangzuweisung erfolgreich durchgef√ºhrt.\")\n",
    "            return rank_map\n",
    "        else:\n",
    "            print(\"‚ùå Rangzuweisung fehlgeschlagen.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Bitte sicherstellen, dass alle Komponenten und Kanten vor der Rangzuweisung definiert sind.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Funktion zur ID-Deduplizierung ===\n",
    "def deduplicate_ids(variables):\n",
    "    seen_ids = {}\n",
    "    updated_variables = {}\n",
    "\n",
    "    for key, var in variables.items():\n",
    "        original_id = var[\"id\"]\n",
    "        label = var.get(\"label\", \"\")\n",
    "\n",
    "        if original_id in seen_ids:\n",
    "            seen_ids[original_id] += 1\n",
    "            new_id = f\"{original_id}_{seen_ids[original_id]}\"\n",
    "        else:\n",
    "            seen_ids[original_id] = 1\n",
    "            new_id = original_id\n",
    "\n",
    "        updated_variables[key] = {\n",
    "            \"id\": new_id,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "    return updated_variables\n",
    "\n",
    "# === JSON-Datei einlesen und Variablen setzen ===\n",
    "def load_instance_json(json_filename):\n",
    "    global instance_data, pattern\n",
    "\n",
    "    try:\n",
    "        with open(json_filename, \"r\") as json_file:\n",
    "            extracted_data = json.load(json_file)\n",
    "            instance_data = extracted_data\n",
    "\n",
    "        # System-Label und Pattern-URI extrahieren\n",
    "        system_label = instance_data.get(\"metadata\", {}).get(\"label\", \"no label\")\n",
    "        raw_pattern_uri = instance_data.get(\"relationships\", {}).get(\"hasCorrespondingPattern\", [None])[0]\n",
    "\n",
    "        # Sicher extrahieren ‚Äì falls kein Pattern vorhanden, als \"no pattern\" setzen\n",
    "        if raw_pattern_uri:\n",
    "            pattern = raw_pattern_uri.split(\".\")[-1] if \"Pattern.\" in raw_pattern_uri else raw_pattern_uri.split(\"/\")[-1]\n",
    "        else:\n",
    "            pattern = \"no pattern\"\n",
    "\n",
    "        pattern_info = f\"üß© Pattern detected: {pattern}\" if pattern != \"no pattern\" else \"‚ö†Ô∏è No pattern detected\"\n",
    "\n",
    "        # IDs deduplizieren\n",
    "        instance_data[\"variables\"] = deduplicate_ids(instance_data.get(\"variables\", {}))\n",
    "\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚úÖ Loaded instance: {system_label}\")\n",
    "            print(f\"üìé raw_pattern_uri: {raw_pattern_uri}\")\n",
    "            print(f\"üß© pattern: {pattern}\")\n",
    "            print(pattern_info)\n",
    "\n",
    "        # Danach weitere Pattern-Entscheidung anzeigen\n",
    "        handle_pattern_selection()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚ùå Error loading JSON:\\n‚Üí {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚ùå Error loading JSON:\\n‚Üí {e}\")\n",
    "\n",
    "# === Button zur Ausf√ºhrung ===\n",
    "load_button = widgets.Button(description=\"Load Extracted JSON\", button_style=\"primary\")\n",
    "def on_load_click(b):\n",
    "    try:\n",
    "        json_file = f\"{selected_system_id}.json\"\n",
    "        load_instance_json(json_file)\n",
    "    except NameError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå No system selected. Please extract a system first.\")\n",
    "\n",
    "load_button.on_click(on_load_click)\n",
    "\n",
    "\n",
    "display(load_button, pattern_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from rdflib import Graph, Namespace, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# === Globals for reuse ===\n",
    "pattern_structure = None\n",
    "pattern_choice = None\n",
    "pattern_graph = None\n",
    "pattern = None\n",
    "\n",
    "# === Variables from previous steps assumed ===\n",
    "# instance_data (dict), pattern (str or \"no pattern\")\n",
    "\n",
    "# === Output containers ===\n",
    "pattern_upload_output = widgets.Output()\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description=\"‚¨áÔ∏è Download Template XML\",\n",
    "    button_style=\"info\",\n",
    "    icon=\"download\"\n",
    ")\n",
    "download_output = widgets.Output()\n",
    "\n",
    "\n",
    "pattern_continue_button = widgets.Button(\n",
    "    description=\"Continue with uploaded pattern\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "# === Upload widget (only shown when needed) ===\n",
    "pattern_upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload Pattern File'\n",
    ")\n",
    "\n",
    "# === Pattern decision: Template or Generate ===\n",
    "pattern_choice_selector = widgets.ToggleButtons(\n",
    "    options=[\n",
    "        (\"Use template\", \"template\"),\n",
    "        (\"Generate automatically\", \"generate\")\n",
    "    ],\n",
    "    description=\"Select Pattern Option:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "# ‚úÖ Template generieren und Download-Button anzeigen\n",
    "def generate_template_from_instance():\n",
    "    print(\"üõ† generate_template_from_instance() aufgerufen\")\n",
    "    global pattern, instance_data, pattern_structure\n",
    "\n",
    "    try:\n",
    "        print(f\"üîç Aktuelles Pattern: {pattern}\")\n",
    "        print(f\"üì¶ instance_data vorhanden: {'instance_data' in globals()}\")\n",
    "        print(f\"üì¶ pattern_structure vorhanden: {'pattern_structure' in globals()}\")\n",
    "\n",
    "        if not pattern or pattern in (\"no pattern\", \"None\", None):\n",
    "            print(\"‚ö†Ô∏è Kein g√ºltiges Pattern gesetzt. Abbruch.\")\n",
    "            return\n",
    "\n",
    "        template_path = f\"Templates/{pattern}.xml\"\n",
    "        print(f\"üìÑ Template-Pfad: {template_path}\")\n",
    "\n",
    "        if not os.path.exists(template_path):\n",
    "            print(f\"‚ùå Template-Datei nicht gefunden: {template_path}\")\n",
    "            return\n",
    "\n",
    "        with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            xml_template = f.read()\n",
    "            print(\"‚úÖ Template-Datei geladen\")\n",
    "\n",
    "        updated_xml = replace_pattern_placeholders(xml_template, instance_data, pattern_structure)\n",
    "        print(\"‚úÖ XML erfolgreich ersetzt\")\n",
    "\n",
    "        # Mapping-Name z.‚ÄØB. nach Instanz-ID setzen\n",
    "        instance_id = instance_data.get(\"id\", \"unknown\")\n",
    "        output_path = f\"Updated_{instance_id}_Workflow.xml\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(updated_xml)\n",
    "\n",
    "        print(f\"‚úÖ Template erfolgreich generiert: {output_path}\")\n",
    "\n",
    "        with download_output:\n",
    "            download_output.clear_output()\n",
    "            file_dl = FileDownload(\n",
    "                data=updated_xml,\n",
    "                filename=output_path,\n",
    "                description=\"‚¨áÔ∏è Download XML\",\n",
    "                button_style=\"success\"\n",
    "            )\n",
    "            display(file_dl)\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"‚ùå Fehler beim Generieren des Templates:\")\n",
    "        traceback.print_exception(type(e), e, e.__traceback__)\n",
    "\n",
    "def handle_pattern_selection():\n",
    "    global pattern, pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "    pattern_upload_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        with pattern_output:\n",
    "            print(f\"üîç DEBUG pattern: {pattern}\")\n",
    "\n",
    "            if pattern is None or pattern == \"no pattern\":\n",
    "                print(\"üìÇ No pattern linked to system. Please upload a pattern TTL file.\")\n",
    "                display(pattern_upload_widget)\n",
    "                display(pattern_continue_button)\n",
    "                display(pattern_upload_output)\n",
    "            else:\n",
    "                print(f\"üß© Pattern detected: {pattern}\")\n",
    "                print(\"How would you like to proceed?\")\n",
    "                display(pattern_choice_selector)\n",
    "\n",
    "                # ‚ùóÔ∏èWICHTIG: Button f√ºr Fortfahren zeigen\n",
    "                display(pattern_decision_continue_button)\n",
    "                pattern_decision_continue_button.layout.display = \"inline-block\"\n",
    "\n",
    "                # üÜï Pattern-Choice merken\n",
    "                pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    except Exception as e:\n",
    "        show_exception(e)\n",
    "\n",
    "\n",
    "        \n",
    "from collections import defaultdict\n",
    "\n",
    "# Output-Widget f√ºr die Plots\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "def on_pattern_decision_continue(b):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        print(\"‚û°Ô∏è Continue decision clicked\")\n",
    "        print(f\"üß≠ Selected option: {pattern_choice}\")\n",
    "\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        elif pattern_choice in [\"generate\", \"upload\"]:\n",
    "            run_component_mapping()\n",
    "            rank_map = apply_positioning_algorithm()\n",
    "\n",
    "            if rank_map:\n",
    "                unordered_layers = defaultdict(list)\n",
    "                for node, rank in rank_map.items():\n",
    "                    unordered_layers[rank].append(node)\n",
    "\n",
    "                ordered_layers = apply_median_heuristic(rank_map, edges, sort_layer_0=True)\n",
    "\n",
    "                # üìä Plotten im Widget\n",
    "                plot_output.clear_output()\n",
    "                with plot_output:\n",
    "                    plot_graph_layout(edges, rank_map, unordered_layers, title=\"Ungeordnete Reihenfolge innerhalb der Layer\")\n",
    "                    plot_graph_layout(edges, rank_map, ordered_layers, title=\"Mit Median-Heuristik geordnete Layer\")\n",
    "\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Keine g√ºltige Option gew√§hlt.\")\n",
    "\n",
    "    pattern_decision_continue_button.layout.display = \"none\"\n",
    "\n",
    "# Button registrieren\n",
    "pattern_decision_continue_button.on_click(on_pattern_decision_continue)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Extract logic from TTL file ===\n",
    "def extract_pattern_structure_from_file(file_path):\n",
    "    g = Graph()\n",
    "    g.parse(file_path, format=\"turtle\")\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology/\")\n",
    "    RES = Namespace(\"http://semantic-systems.net/swemls/\")\n",
    "\n",
    "    def clean_uri(uri):\n",
    "        label = uri.split(\"/\")[-1].split(\"#\")[-1]\n",
    "        label = re.sub(r'Pattern\\.[A-Za-z0-9]+\\.', '', label)\n",
    "        label = re.sub(r'^[A-Za-z0-9]+\\.', '', label)\n",
    "        return label\n",
    "\n",
    "    structure = {\"steps\": {}, \"variables\": {}}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    return structure\n",
    "\n",
    "# === Trigger on pattern upload ===\n",
    "def on_pattern_upload(change):\n",
    "    global pattern_structure\n",
    "\n",
    "    if not pattern_upload_widget.value:\n",
    "        return\n",
    "\n",
    "    uploaded = next(iter(pattern_upload_widget.value.items()))  # (filename, fileinfo)\n",
    "    file_name = uploaded[0]\n",
    "    file_content = uploaded[1]['content']\n",
    "\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(file_content)\n",
    "\n",
    "    with pattern_output:\n",
    "        clear_output()\n",
    "        print(f\"‚úÖ Pattern file uploaded: {file_name}\")\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_name)\n",
    "        with pattern_output:\n",
    "            print(\"‚úÖ Extracted pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"‚ùå Error parsing pattern file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pattern_upload_widget.observe(on_pattern_upload, names='value')\n",
    "\n",
    "\n",
    "\n",
    "def on_pattern_choice(change):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = change['new']\n",
    "    file_path = f\"Patterns/{pattern}-pattern.ttl\"\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_path)\n",
    "\n",
    "        with pattern_output:\n",
    "            print(f\"‚úÖ Pattern '{pattern}' loaded from: {file_path}\")\n",
    "            print(f\"üß© Pattern mode selected: {pattern_choice}\")\n",
    "            print(\"üìä Pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "\n",
    "        # ‚¨ÖÔ∏è Template ausf√ºhren, wenn Template gew√§hlt wurde\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        # üÜï Wenn nicht Template, Button wieder anzeigen!\n",
    "        if pattern_choice in [\"generate\", \"upload\"]:\n",
    "            pattern_decision_continue_button.layout.display = \"inline-block\"\n",
    "            display(pattern_decision_continue_button)\n",
    "\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"‚ùå Error reading pattern file: {file_path}\")\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "pattern_choice_selector.observe(on_pattern_choice, names='value')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "main_pattern_box = widgets.VBox([\n",
    "    pattern_output,\n",
    "    pattern_upload_output,\n",
    "    download_output  # üÜï Zeigt den Download-Link nach Template-Erstellung\n",
    "])\n",
    "\n",
    "\n",
    "# Button-Handler aktivieren ‚¨áÔ∏è\n",
    "pattern_continue_button.on_click(on_pattern_continue)\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "handle_pattern_selection()\n",
    "display(main_pattern_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import os\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# === Globale Ausgabe-Widgets ===\n",
    "download_output = widgets.Output()\n",
    "\n",
    "# === Funktion zur Fehlerausgabe ===\n",
    "def show_exception(e):\n",
    "    print(\"‚ùå Exception caught:\")\n",
    "    traceback.print_exception(type(e), e, e.__traceback__, file=sys.stdout)\n",
    "\n",
    "# === Funktion zum Extrahieren des Labels aus einem Schritt ===\n",
    "def extract_label_short(step):\n",
    "    labels = step.get(\"metadata\", {}).get(\"label\", [])\n",
    "    if labels:\n",
    "        match = re.search(r\"\\((.*?)\\)\", labels[0])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return step[\"id\"].split(\".\")[-1]\n",
    "\n",
    "# === Funktion zum Ersetzen der Platzhalter im XML ===\n",
    "def replace_pattern_placeholders(xml_string, instance_data, pattern_structure):\n",
    "    with download_output:\n",
    "        print(\"\\U0001f527 replace_pattern_placeholders() aufgerufen\")\n",
    "        print(f\"\\U0001f527 XML L√§nge: {len(xml_string)}\")\n",
    "        print(f\"\\U0001f527 Instance data keys: {list(instance_data.keys())}\")\n",
    "        print(f\"\\U0001f527 Pattern structure keys: {list(pattern_structure.keys())}\")\n",
    "\n",
    "    tree = ET.ElementTree(ET.fromstring(xml_string))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    replacements = {}\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\U0001f501 Schritte werden ersetzt...\")\n",
    "    for step in instance_data.get(\"steps\", []):\n",
    "        step_key = step[\"id\"].split(\".\")[-1]\n",
    "        step_label = extract_label_short(step)\n",
    "        replacements[step_key] = step_label\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\U0001f501 Variablen werden ersetzt...\")\n",
    "    for pattern_var in pattern_structure.get(\"variables\", {}):\n",
    "        for var_key, var_data in instance_data.get(\"variables\", {}).items():\n",
    "            if pattern_var.lower() in var_key.lower():\n",
    "                inst_id = var_data[\"id\"].replace(\"Resource.\", \"\").replace(\"Custom.\", \"\")\n",
    "                replacements[pattern_var] = inst_id\n",
    "                break\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\n\\U0001f9e9 Mapping for replacements:\")\n",
    "        for k, v in replacements.items():\n",
    "            print(f\"  {k} ‚Üí {v}\")\n",
    "\n",
    "    for element in root.iter(\"mxCell\"):\n",
    "        if 'value' in element.attrib:\n",
    "            value = element.attrib['value']\n",
    "            for placeholder, real_value in replacements.items():\n",
    "                if placeholder in value:\n",
    "                    replacement = real_value.replace(\"_\", \" \") if real_value.strip() else \"Missing\"\n",
    "                    style = element.attrib.get(\"style\", \"\")\n",
    "                    length = len(replacement)\n",
    "                    if length > 24:\n",
    "                        style += \";fontSize=5\"\n",
    "                    elif length > 20:\n",
    "                        style += \";fontSize=7\"\n",
    "                    elif length > 17:\n",
    "                        style += \";fontSize=9\"\n",
    "                    element.attrib['style'] = style\n",
    "                    element.attrib['value'] = value.replace(placeholder, replacement)\n",
    "\n",
    "    return ET.tostring(root, encoding='utf-8', method='xml').decode()\n",
    "\n",
    "# === Template generieren und Base64-Download-Link anzeigen ===\n",
    "def generate_template_from_instance():\n",
    "    global pattern, instance_data, pattern_structure\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        try:\n",
    "            print(\"\\U0001f6e0 generate_template_from_instance() aufgerufen\")\n",
    "            print(f\"\\U0001f50d Aktuelles Pattern: {pattern}\")\n",
    "            print(f\"\\U0001f4e6 instance_data vorhanden: {'instance_data' in globals()}\")\n",
    "            print(f\"\\U0001f4e6 pattern_structure vorhanden: {pattern_structure is not None}\")\n",
    "\n",
    "            if not pattern or pattern in (\"no pattern\", \"None\", None):\n",
    "                print(\"‚ö†Ô∏è Kein g√ºltiges Pattern gesetzt. Abbruch.\")\n",
    "                return\n",
    "\n",
    "            template_path = f\"Templates/{pattern}.xml\"\n",
    "            print(f\"\\U0001f4c4 Template-Pfad: {template_path}\")\n",
    "\n",
    "            if not os.path.exists(template_path):\n",
    "                print(f\"‚ùå Template-Datei nicht gefunden: {template_path}\")\n",
    "                return\n",
    "\n",
    "            with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                xml_template = f.read()\n",
    "                print(f\"‚úÖ Template-Datei geladen mit L√§nge {len(xml_template)}\")\n",
    "\n",
    "            updated_xml = replace_pattern_placeholders(xml_template, instance_data, pattern_structure)\n",
    "            print(\"‚úÖ XML erfolgreich ersetzt\")\n",
    "\n",
    "            instance_id = instance_data.get(\"id\", \"unknown\")\n",
    "            filename = f\"Updated_{instance_id}_Workflow.xml\"\n",
    "\n",
    "            # Base64 codieren und HTML-Link erstellen\n",
    "            b64 = base64.b64encode(updated_xml.encode()).decode()\n",
    "            href = f'data:application/xml;base64,{b64}'\n",
    "            display(HTML(f'<a download=\"{filename}\" href=\"{href}\" target=\"_blank\">‚¨áÔ∏è Click here to download the XML file</a>'))\n",
    "            print(f\"‚úÖ Datei bereit: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Fehler beim Generieren des Templates:\")\n",
    "            traceback.print_exception(type(e), e, e.__traceback__)\n",
    "\n",
    "# üÜï Entscheidung durchf√ºhren Button\n",
    "pattern_decision_continue_button = widgets.Button(\n",
    "    description=\"Continue with selected option\",\n",
    "    button_style=\"primary\",\n",
    "    icon=\"check\"\n",
    ")\n",
    "\n",
    "def on_pattern_decision_continue(b):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    # üß† Absicherung: Wenn noch kein pattern_structure geladen, dann jetzt laden\n",
    "    if pattern_structure is None and pattern and pattern_choice == \"template\":\n",
    "        try:\n",
    "            file_path = f\"Patterns/{pattern}-pattern.ttl\"\n",
    "            pattern_structure = extract_pattern_structure_from_file(file_path)\n",
    "            print(f\"‚úÖ Pattern structure nachgeladen aus: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Nachladen der Patternstruktur: {e}\")\n",
    "            return\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        print(\"‚û°Ô∏è Continue decision clicked\")\n",
    "        print(f\"üß≠ Selected option: {pattern_choice}\")\n",
    "\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        elif pattern_choice in [\"generate\", \"upload\"]:\n",
    "            run_component_mapping()\n",
    "            rank_map = apply_positioning_algorithm()\n",
    "\n",
    "            # ‚úÖ Visualisierung starten, wenn Rangzuweisung erfolgreich war\n",
    "            if rank_map:\n",
    "                unordered_layers = defaultdict(list)\n",
    "                for node, rank in rank_map.items():\n",
    "                    unordered_layers[rank].append(node)\n",
    "\n",
    "                ordered_layers = apply_median_heuristic(rank_map, edges, sort_layer_0=True)\n",
    "\n",
    "                plot_output.clear_output()\n",
    "                with plot_output:\n",
    "                    print(\"üìä Visualisierung der Workflows:\")\n",
    "                    plot_graph_layout(edges, rank_map, unordered_layers, title=\"Ungeordnete Reihenfolge innerhalb der Layer\")\n",
    "                    plot_graph_layout(edges, rank_map, ordered_layers, title=\"Mit Median-Heuristik geordnete Layer\")\n",
    "\n",
    "                display(plot_output)\n",
    "            else:\n",
    "                with plot_output:\n",
    "                    print(\"‚ö†Ô∏è Rangberechnung fehlgeschlagen ‚Äì keine Visualisierung m√∂glich.\")\n",
    "                display(plot_output)\n",
    "\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Keine g√ºltige Option gew√§hlt.\")\n",
    "\n",
    "    pattern_decision_continue_button.layout.display = \"none\"\n",
    "\n",
    "\n",
    "pattern_decision_continue_button.on_click(on_pattern_decision_continue)\n",
    "\n",
    "# üÜï Anzeige des Buttons und Ausgabecontainers\n",
    "display(pattern_decision_continue_button, download_output)\n",
    "\n",
    "# ‚úÖ Anzeigen im Notebook\n",
    "display(component_mapping_output, edge_mapping_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_crossings(layers: Dict[int, List[str]], edges: List[Tuple[str, str]]) -> int:\n",
    "    pos_in_layer = {node: (rank, i) for rank, nodes in layers.items() for i, node in enumerate(nodes)}\n",
    "    crossings = 0\n",
    "    for (u1, v1), (u2, v2) in itertools.combinations(edges, 2):\n",
    "        if u1 not in pos_in_layer or v1 not in pos_in_layer or u2 not in pos_in_layer or v2 not in pos_in_layer:\n",
    "            continue\n",
    "        r1_u, x1_u = pos_in_layer[u1]\n",
    "        r1_v, x1_v = pos_in_layer[v1]\n",
    "        r2_u, x2_u = pos_in_layer[u2]\n",
    "        r2_v, x2_v = pos_in_layer[v2]\n",
    "        if r1_v != r2_v:\n",
    "            continue  # Only compare edges in the same layer\n",
    "        if (x1_u - x2_u) * (x1_v - x2_v) < 0:\n",
    "            crossings += 1\n",
    "    return crossings\n",
    "\n",
    "def greedy_swap_optimization(layers: Dict[int, List[str]], edges: List[Tuple[str, str]], iterations: int = 10) -> Dict[int, List[str]]:\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    new_layers = {r: list(nodes) for r, nodes in layers.items()}  # Copy\n",
    "    print(\"\\nüîÅ Starte Greedy-Swap Optimierung...\\n\")\n",
    "    for r in sorted(new_layers):\n",
    "        if r == 0:\n",
    "            continue  # Don't optimize layer 0\n",
    "        improved = True\n",
    "        while improved:\n",
    "            improved = False\n",
    "            current = new_layers[r]\n",
    "            for i in range(len(current) - 1):\n",
    "                swapped = list(current)\n",
    "                swapped[i], swapped[i+1] = swapped[i+1], swapped[i]\n",
    "                temp_layers = dict(new_layers)\n",
    "                temp_layers[r] = swapped\n",
    "                old_crossings = count_crossings(new_layers, edges)\n",
    "                new_crossings = count_crossings(temp_layers, edges)\n",
    "                if new_crossings < old_crossings:\n",
    "                    print(f\"  ‚úÖ Swap: {current[i]} ‚¨å {current[i+1]} reduziert Kreuzungen: {old_crossings} ‚Üí {new_crossings}\")\n",
    "                    new_layers[r] = swapped\n",
    "                    improved = True\n",
    "                    break\n",
    "    return new_layers\n",
    "\n",
    "def apply_median_heuristic(rank_map: Dict[str, int], edges: List[Tuple[str, str]], sort_layer_0: bool = False) -> Dict[int, List[str]]:\n",
    "    print(\"\\nüîß Starte Median-Heuristik zur Anordnung der Knoten innerhalb von R√§ngen...\\n\")\n",
    "    layers = defaultdict(list)\n",
    "    for node, rank in rank_map.items():\n",
    "        layers[rank].append(node)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    ordered_layers = {}\n",
    "    for r in sorted(layers.keys()):\n",
    "        if r == 0 and not sort_layer_0:\n",
    "            ordered_layers[r] = layers[r]\n",
    "            continue\n",
    "        def median(node):\n",
    "            preds = list(G.predecessors(node))\n",
    "            if not preds:\n",
    "                return float('inf')\n",
    "            return sum([layers[rank_map[pred]].index(pred) for pred in preds if pred in layers[rank_map[pred]]]) / len(preds)\n",
    "        sorted_nodes = sorted(layers[r], key=median)\n",
    "        ordered_layers[r] = sorted_nodes\n",
    "    print(\"üìä Ergebnis der Median-Heuristik:\")\n",
    "    for rank in sorted(ordered_layers):\n",
    "        print(f\"  Rang {rank}: {ordered_layers[rank]}\")\n",
    "    return ordered_layers\n",
    "\n",
    "def plot_graph_layout(edges: List[Tuple[str, str]], rank_map: Dict[str, int], layer_nodes: Dict[int, List[str]], title: str = \"Graph Layout\") -> None:\n",
    "    pos = {}\n",
    "    x_spacing = 2\n",
    "    y_spacing = 2\n",
    "    for r, nodes in sorted(layer_nodes.items()):\n",
    "        for i, node in enumerate(nodes):\n",
    "            pos[node] = (i * x_spacing, -r * y_spacing)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=8, arrows=True)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# Am Ende des Notebooks:\n",
    "display(plot_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
