{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "\n",
    "def show_exception(e):\n",
    "    print(\"âŒ Exception caught:\")\n",
    "    traceback.print_exception(type(e), e, e.__traceback__, file=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rdflib import Graph, Namespace\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "\n",
    "shacl_output = widgets.Output()\n",
    "\n",
    "# === SHACL-Regeln anwenden auf hochgeladene Datei ===\n",
    "def apply_shacl_rules(instance_file_path: str) -> Graph:\n",
    "    SH = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    shapes_dir = \"Shapes\"  # relative Pfadangabe im Repo\n",
    "\n",
    "    shape_files = [\n",
    "        \"_generic-shapes.ttl\", \"A1-shapes.ttl\", \"A2-shapes.ttl\", \"A3-shapes.ttl\",\n",
    "        \"F1-shapes.ttl\", \"F2-shapes.ttl\", \"F3-shapes.ttl\", \"F4-shapes.ttl\",\n",
    "        \"I1-shapes.ttl\", \"I2-shapes.ttl\", \"I3-shapes.ttl\", \"I4-shapes.ttl\",\n",
    "        \"I5-shapes.ttl\", \"I6-shapes.ttl\", \"I7-shapes.ttl\", \"O1-shapes.ttl\",\n",
    "        \"O2-shapes.ttl\", \"O3-shapes.ttl\", \"O4-shapes.ttl\", \"T1-shapes.ttl\",\n",
    "        \"T2-shapes.ttl\", \"T3-shapes.ttl\", \"T4-shapes.ttl\", \"T5-shapes.ttl\",\n",
    "        \"T6-shapes.ttl\", \"T7-shapes.ttl\", \"T8-shapes.ttl\", \"T9-shapes.ttl\",\n",
    "        \"T10-shapes.ttl\", \"T11-shapes.ttl\", \"T12-shapes.ttl\", \"T13-shapes.ttl\",\n",
    "        \"T14-shapes.ttl\", \"T15-shapes.ttl\", \"T16-shapes.ttl\", \"T17-shapes.ttl\",\n",
    "        \"T18-shapes.ttl\", \"T19-shapes.ttl\", \"T20-shapes.ttl\", \"T21-shapes.ttl\",\n",
    "        \"T22-shapes.ttl\", \"T23-shapes.ttl\", \"Y1-shapes.ttl\", \"Y2-shapes.ttl\", \"Y4-shapes.ttl\"\n",
    "    ]\n",
    "\n",
    "    g_instance = Graph()\n",
    "    g_instance.parse(instance_file_path, format=\"turtle\")\n",
    "\n",
    "    triples_before = len(g_instance)\n",
    "\n",
    "    for shape_file in shape_files:\n",
    "        shape_path = os.path.join(shapes_dir, shape_file)\n",
    "        g_shape = Graph()\n",
    "\n",
    "        if not os.path.exists(shape_path):\n",
    "            with shacl_output:\n",
    "                print(f\"âš ï¸ Shape file not found: {shape_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            g_shape.parse(shape_path, format=\"turtle\")\n",
    "            with shacl_output:\n",
    "                print(f\"âœ… Loaded SHACL shape file: {shape_file}\")\n",
    "        except Exception as e:\n",
    "            with shacl_output:\n",
    "                print(f\"âŒ Error loading {shape_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for rule in g_shape.subjects(predicate=SH.rule, object=None):\n",
    "            for _, _, construct_query in g_shape.triples((rule, SH.construct, None)):\n",
    "                query = str(construct_query)\n",
    "                try:\n",
    "                    g_instance.update(query)\n",
    "                except Exception as e:\n",
    "                    with shacl_output:\n",
    "                        print(f\"âŒ Error executing rule from {shape_file}: {e}\")\n",
    "\n",
    "    triples_after = len(g_instance)\n",
    "    with shacl_output:\n",
    "        print(\"âœ… All rules applied.\")\n",
    "        print(f\"ğŸ“Š Triples before: {triples_before}\")\n",
    "        print(f\"ğŸ“ˆ Triples after: {triples_after}\")\n",
    "        print(f\"â• Added: {triples_after - triples_before} triples\")\n",
    "\n",
    "    return g_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from rdflib import Graph\n",
    "\n",
    "# === Globale Variablen ===\n",
    "instance_file_path = None\n",
    "output = widgets.Output()\n",
    "result_graph = None\n",
    "\n",
    "\n",
    "\n",
    "# === Auswahlfeld: Beispiel oder Upload ===\n",
    "option_selector = widgets.ToggleButtons(\n",
    "    options=[(\"Use example file\", \"example\"), (\"Upload your own\", \"upload\")],\n",
    "    description=\"Select input:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# === Upload-Widget (immer sichtbar) ===\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload TTL file'\n",
    ")\n",
    "\n",
    "# === \"Continue\"-Button ===\n",
    "continue_button = widgets.Button(description=\"Continue\", button_style='primary')\n",
    "\n",
    "# === Auswahlhandler ===\n",
    "def on_option_change(change):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        if change['new'] == 'example':\n",
    "            global instance_file_path\n",
    "            instance_file_path = \"Instance_Files/swemls-instances.ttl\"\n",
    "            print(f\"ğŸ“ Example file selected:\\nâ†’ {instance_file_path}\")\n",
    "        elif change['new'] == 'upload':\n",
    "            print(\"ğŸ“¤ Please upload a TTL file using the field below.\")\n",
    "\n",
    "option_selector.observe(on_option_change, names='value')\n",
    "\n",
    "# === Upload-Handler ===\n",
    "def on_upload(change):\n",
    "    global instance_file_path\n",
    "    if upload_widget.value:\n",
    "        uploaded = upload_widget.value[0]\n",
    "        file_name = uploaded['name']\n",
    "        instance_file_path = file_name\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(uploaded['content'])\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(f\"âœ… File uploaded and saved as:\\nâ†’ {file_name}\")\n",
    "\n",
    "upload_widget.observe(on_upload, names='value')\n",
    "\n",
    "# === Continue-Button-Handler ===\n",
    "def on_continue(b):\n",
    "    global result_graph\n",
    "    output.clear_output()\n",
    "    if not instance_file_path:\n",
    "        with output:\n",
    "            print(\"âš ï¸ No file selected or uploaded.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(instance_file_path):\n",
    "        with output:\n",
    "            print(f\"âŒ File not found on disk:\\nâ†’ {instance_file_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if instance_file_path.endswith(\".ttl\") and not instance_file_path.startswith(\"Instance_Files/\"):\n",
    "            with output:\n",
    "                print(\"ğŸ” SHACL rules will be applied to uploaded file.\")\n",
    "            result_graph = apply_shacl_rules(instance_file_path)\n",
    "        else:\n",
    "            g = Graph()\n",
    "            g.parse(instance_file_path, format=\"turtle\")\n",
    "            result_graph = g\n",
    "\n",
    "        with output:\n",
    "            print(f\"âœ… RDF file successfully loaded!\")\n",
    "            print(f\"ğŸ“„ Triples in graph: {len(result_graph)}\")\n",
    "            print(f\"ğŸ”— Using file:\\nâ†’ {instance_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"âŒ Error parsing TTL file:\\nâ†’ {e}\")\n",
    "\n",
    "    # â¬‡ï¸ SHACL-Ausgabe sichtbar machen\n",
    "    display(shacl_output)\n",
    "\n",
    "continue_button.on_click(on_continue)\n",
    "\n",
    "# === Anzeige aller Elemente ===\n",
    "display(option_selector, upload_widget, continue_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from rdflib.namespace import RDF\n",
    "from IPython.display import display\n",
    "\n",
    "# Outputs\n",
    "query_interface_output = widgets.Output()\n",
    "selection_output = widgets.Output()\n",
    "\n",
    "# SPARQL Query-Feld\n",
    "query_input = widgets.Textarea(\n",
    "    value=\"\"\"\n",
    "PREFIX swemls: <https://w3id.org/semsys/ns/swemls#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?system\n",
    "WHERE {\n",
    "  ?system a swemls:System .\n",
    "  ?system swemls:hasCorrespondingPattern ?pattern .\n",
    "  FILTER(STRENDS(STR(?pattern), \"O1\"))\n",
    "}\n",
    "\"\"\",\n",
    "    placeholder='Enter your SPARQL query here...',\n",
    "    description='SPARQL Query:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Buttons\n",
    "run_query_button = widgets.Button(description=\"Run Query\", button_style='primary')\n",
    "confirm_button = widgets.Button(description=\"Confirm selection\", button_style='success')\n",
    "\n",
    "# Dropdown fÃ¼r Systeme\n",
    "system_selector = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description=\"Select system:\",\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Globales Ergebnis\n",
    "matched_systems = []\n",
    "\n",
    "# Query-Handler\n",
    "def on_query_run(b):\n",
    "    global matched_systems\n",
    "    query_interface_output.clear_output()\n",
    "    selection_output.clear_output()\n",
    "    system_selector.options = []\n",
    "\n",
    "    if 'result_graph' not in globals() or result_graph is None:\n",
    "        with query_interface_output:\n",
    "            print(\"âš ï¸ RDF graph not loaded.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        results = result_graph.query(query_input.value)\n",
    "    except Exception as e:\n",
    "        with query_interface_output:\n",
    "            print(f\"âŒ Query error: {e}\")\n",
    "        return\n",
    "\n",
    "    matched_systems = []\n",
    "    for row in results:\n",
    "        uri = str(row.system)\n",
    "        sys_id = uri.split(\"/\")[-1]\n",
    "        matched_systems.append((sys_id, uri))\n",
    "\n",
    "    if not matched_systems:\n",
    "        with query_interface_output:\n",
    "            print(\"âš ï¸ No matching systems found.\")\n",
    "        return\n",
    "\n",
    "    system_selector.options = [(sys_id, uri) for sys_id, uri in matched_systems]\n",
    "\n",
    "    with query_interface_output:\n",
    "        print(f\"âœ… Found {len(matched_systems)} matching system(s):\")\n",
    "        for i, (sys_id, _) in enumerate(matched_systems):\n",
    "            print(f\" {i+1}: {sys_id}\")\n",
    "\n",
    "# Auswahl-Handler\n",
    "def on_confirm_selection(b):\n",
    "    global selected_system_id, selected_system_uri\n",
    "    selected_label = system_selector.label\n",
    "    selected_uri = system_selector.value\n",
    "    selected_system_id = selected_label\n",
    "    selected_system_uri = selected_uri\n",
    "    with selection_output:\n",
    "        selection_output.clear_output()\n",
    "        print(f\"âœ… You selected: {selected_system_id}\")\n",
    "        print(f\"ğŸ”— URI: {selected_system_uri}\")\n",
    "\n",
    "# Event-Bindings\n",
    "run_query_button.on_click(on_query_run)\n",
    "confirm_button.on_click(on_confirm_selection)\n",
    "\n",
    "# Anzeigen\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        query_input,\n",
    "        run_query_button,\n",
    "        query_interface_output,\n",
    "        widgets.HBox([system_selector, confirm_button]),\n",
    "        selection_output\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "json_output = widgets.Output()\n",
    "\n",
    "def extract_and_export_selected_system():\n",
    "    global selected_system_id, selected_system_uri, result_graph\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology#\")\n",
    "    RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "    rdf_type = URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\")\n",
    "    ai_system_type = SWEMLS.System\n",
    "    documentation_type = SWEMLS.Documentation\n",
    "    paper_type = SWEMLS.Paper\n",
    "    ml_component_type = SWEMLS.MachineLearningComponent\n",
    "    kr_component_type = SWEMLS.KnowledgeRepresentationComponent\n",
    "    data_type = SWEMLS.Data\n",
    "    semantic_web_resource_type = SWEMLS.SemanticWebResource\n",
    "    has_documentation = SWEMLS.hasDocumentation\n",
    "    reports_on = SWEMLS.reports\n",
    "    rdfs_label = RDFS.label\n",
    "\n",
    "    g = result_graph\n",
    "\n",
    "    # 1. System und zugehÃ¶rige Paper finden\n",
    "    ai_systems = [\n",
    "        system for system in g.subjects(RDF.type, ai_system_type)\n",
    "        if str(system).split(\"/\")[-1] == selected_system_id\n",
    "    ]\n",
    "\n",
    "    system_to_paper = {}\n",
    "    for paper in g.subjects(predicate=rdf_type, object=paper_type):\n",
    "        for reported_system in g.objects(subject=paper, predicate=reports_on):\n",
    "            system_id = str(reported_system).split(\"/\")[-1]\n",
    "            paper_id = str(paper).split(\"/\")[-1]\n",
    "            paper_metadata = {\"id\": paper_id, \"metadata\": {}}\n",
    "            for pred, obj in g.predicate_objects(subject=paper):\n",
    "                pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "                paper_metadata[\"metadata\"].setdefault(pred_name, []).append(str(obj))\n",
    "            system_to_paper.setdefault(system_id, []).append(paper_metadata)\n",
    "\n",
    "    # 2. System extrahieren\n",
    "    for system in ai_systems:\n",
    "        instance_data = {\n",
    "            \"id\": str(system).split(\"/\")[-1],\n",
    "            \"type\": \"System\",\n",
    "            \"metadata\": {},\n",
    "            \"relationships\": {},\n",
    "            \"documentation\": {},\n",
    "            \"papers\": [],\n",
    "            \"steps\": [],\n",
    "            \"variables\": {}\n",
    "        }\n",
    "\n",
    "        for pred, obj in g.predicate_objects(subject=system):\n",
    "            pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "            if isinstance(obj, URIRef):\n",
    "                instance_data[\"relationships\"].setdefault(pred_name, []).append(str(obj).split(\"/\")[-1])\n",
    "            else:\n",
    "                instance_data[\"metadata\"][pred_name] = str(obj)\n",
    "\n",
    "        # 3. Dokumentation extrahieren\n",
    "        if \"hasDocumentation\" in instance_data[\"relationships\"]:\n",
    "            for doc_id in instance_data[\"relationships\"][\"hasDocumentation\"]:\n",
    "                doc_uri = URIRef(f\"http://semantic-systems.net/swemls/{doc_id}\")\n",
    "                if (doc_uri, rdf_type, documentation_type) in g:\n",
    "                    instance_data[\"documentation\"][\"id\"] = doc_id\n",
    "                    for doc_pred, doc_obj in g.predicate_objects(subject=doc_uri):\n",
    "                        doc_pred_name = doc_pred.split(\"#\")[-1] if \"#\" in doc_pred else doc_pred.split(\"/\")[-1]\n",
    "                        instance_data[\"documentation\"][doc_pred_name] = str(doc_obj)\n",
    "\n",
    "        # 4. Paper hinzufÃ¼gen\n",
    "        if selected_system_id in system_to_paper:\n",
    "            instance_data[\"papers\"] = system_to_paper[selected_system_id]\n",
    "\n",
    "        # 5. Schritte (ML/KR) extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for step_relation in [f\"hasStepML{i}\", f\"hasStepKR{i}\"]:\n",
    "                if step_relation in instance_data[\"relationships\"]:\n",
    "                    for step_id in instance_data[\"relationships\"][step_relation]:\n",
    "                        step_uri = URIRef(f\"http://semantic-systems.net/swemls/{step_id}\")\n",
    "                        step_type = \"Unknown\"\n",
    "                        if (step_uri, rdf_type, ml_component_type) in g:\n",
    "                            step_type = \"Machine Learning\"\n",
    "                        elif (step_uri, rdf_type, kr_component_type) in g:\n",
    "                            step_type = \"Knowledge Representation\"\n",
    "                        step_data = {\"id\": step_id, \"type\": step_type, \"metadata\": {}}\n",
    "                        for step_pred, step_obj in g.predicate_objects(subject=step_uri):\n",
    "                            step_pred_name = step_pred.split(\"#\")[-1] if \"#\" in step_pred else step_pred.split(\"/\")[-1]\n",
    "                            step_data[\"metadata\"].setdefault(step_pred_name, []).append(str(step_obj))\n",
    "                        instance_data[\"steps\"].append(step_data)\n",
    "\n",
    "        # 6. Variablen extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for var_relation in [f\"hasVariableData{i}\", f\"hasVariableSW{i}\"]:\n",
    "                if var_relation in instance_data[\"relationships\"]:\n",
    "                    for var_id in instance_data[\"relationships\"][var_relation]:\n",
    "                        var_uri = URIRef(f\"http://semantic-systems.net/swemls/{var_id}\")\n",
    "                        label = None\n",
    "                        for _, _, label_value in g.triples((var_uri, rdfs_label, None)):\n",
    "                            label = str(label_value)\n",
    "                            break\n",
    "                        instance_data[\"variables\"][var_relation] = {\"id\": var_id, \"label\": label}\n",
    "\n",
    "        # 7. Speichern\n",
    "        json_filename = f\"{selected_system_id}.json\"\n",
    "        with open(json_filename, \"w\") as f:\n",
    "            json.dump(instance_data, f, indent=4)\n",
    "\n",
    "        with json_output:\n",
    "            json_output.clear_output()\n",
    "            print(f\"âœ… JSON successfully exported as: {json_filename}\")\n",
    "            print(json.dumps(instance_data, indent=2))  # Ausgabe fÃ¼r ÃœberprÃ¼fung\n",
    "\n",
    "# === Button zum Starten der Extraktion ===\n",
    "extract_button = widgets.Button(description=\"Extract JSON\", button_style=\"success\")\n",
    "extract_button.on_click(lambda b: extract_and_export_selected_system())\n",
    "\n",
    "display(extract_button, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "pattern_output = widgets.Output()\n",
    "\n",
    "# === Component Mapping fÃ¼r automatische Generierung oder Pattern-Upload ===\n",
    "import re\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def run_component_mapping():\n",
    "    global components, json_to_pattern_map, edges\n",
    "\n",
    "    display(\"ğŸ§© Starte Component Mapping ...\")\n",
    "\n",
    "    # Schritt 1: Mapping von JSON zu Pattern-KÃ¼rzeln (Verwendung der ID anstelle des Labels)\n",
    "    json_to_pattern_map = {}\n",
    "\n",
    "    for step in instance_data[\"steps\"]:\n",
    "        step_key = step[\"id\"].split(\".\")[-1]  # Extrahiere die ID des Schrittes\n",
    "        json_to_pattern_map[step_key] = step[\"id\"]  # Speichere die ID statt des Labels\n",
    "\n",
    "    for var_key, var_data in instance_data[\"variables\"].items():\n",
    "        json_to_pattern_map[var_key] = var_data[\"id\"]  # Verwende die ID der Variablen\n",
    "\n",
    "    for var_data in instance_data[\"variables\"].values():\n",
    "        key = var_data[\"id\"].split(\".\")[-1]\n",
    "        if key not in json_to_pattern_map:\n",
    "            json_to_pattern_map[key] = var_data[\"id\"]\n",
    "\n",
    "    # Schritt 2: Komponentenstruktur initialisieren\n",
    "    components = {\n",
    "        \"ml_component\": [],\n",
    "        \"kr_component\": [],\n",
    "        \"data\": [],\n",
    "        \"symbolic_data\": []\n",
    "    }\n",
    "\n",
    "    for step in instance_data[\"steps\"]:\n",
    "        step_type_list = step.get(\"metadata\", {}).get(\"type\", [])\n",
    "        step_type = step_type_list[-1] if step_type_list else \"\"\n",
    "        if \"MachineLearningComponent\" in step_type and step[\"id\"] not in components[\"ml_component\"]:\n",
    "            components[\"ml_component\"].append(step[\"id\"])\n",
    "        elif \"KnowledgeRepresentationComponent\" in step_type and step[\"id\"] not in components[\"kr_component\"]:\n",
    "            components[\"kr_component\"].append(step[\"id\"])\n",
    "\n",
    "    for var_relation, var_data in instance_data[\"variables\"].items():\n",
    "        if \"SW\" in var_relation:\n",
    "            components[\"symbolic_data\"].append(var_data[\"id\"])\n",
    "        else:\n",
    "            components[\"data\"].append(var_data[\"id\"])\n",
    "\n",
    "    # Schritt 3: Fehlende Variablen im Pattern ergÃ¤nzen\n",
    "    for key in set(json_to_pattern_map.keys()) - set(pattern_structure[\"variables\"].keys()):\n",
    "        pattern_structure[\"variables\"][key] = {\"generated_by\": []}\n",
    "\n",
    "    # Schritt 4: Letzter Check auf fehlende Nodes\n",
    "    missing_nodes = set(json_to_pattern_map.keys()) - set(pattern_structure[\"variables\"].keys()) - set(pattern_structure[\"steps\"].keys())\n",
    "    if missing_nodes:\n",
    "        display(f\" âš ï¸ WARNING: Nodes still missing after fix: {missing_nodes}\")\n",
    "\n",
    "    # === Edge Mapping ===\n",
    "    display(\"\\nğŸ”— Starte Edge Mapping...\")\n",
    "\n",
    "    edges = []  # Initialize edges list\n",
    "\n",
    "    # Dynamische Zuordnung spezieller Variablen\n",
    "    special_mappings = {f\"Data{i}\": f\"hasVariableData{i}\" for i in range(1, 11)}\n",
    "    special_mappings.update({f\"SW{i}\": f\"hasVariableSW{i}\" for i in range(1, 11)})\n",
    "\n",
    "    # Fehlende Pattern-Variablen ergÃ¤nzen\n",
    "    for var_name in pattern_structure[\"variables\"]:\n",
    "        if var_name not in json_to_pattern_map:\n",
    "            found_match = False\n",
    "\n",
    "            if var_name in special_mappings:\n",
    "                mapped_var = instance_data[\"variables\"].get(special_mappings[var_name], {}).get(\"id\")\n",
    "                if mapped_var:\n",
    "                    json_to_pattern_map[var_name] = mapped_var\n",
    "                    found_match = True\n",
    "\n",
    "            if not found_match:\n",
    "                for var_key, var_data in instance_data[\"variables\"].items():\n",
    "                    if var_name.lower() in var_key.lower():\n",
    "                        json_to_pattern_map[var_name] = var_data[\"id\"]\n",
    "                        found_match = True\n",
    "                        break\n",
    "\n",
    "            if not found_match:\n",
    "                for rel_key, rel_values in instance_data[\"relationships\"].items():\n",
    "                    if isinstance(rel_values, list):\n",
    "                        for value in rel_values:\n",
    "                            if var_name.lower() == value.split(\".\")[-1].lower():\n",
    "                                json_to_pattern_map[var_name] = value\n",
    "                                found_match = True\n",
    "                                break\n",
    "                    if found_match:\n",
    "                        break\n",
    "\n",
    "            if not found_match:\n",
    "                json_to_pattern_map[var_name] = var_name\n",
    "\n",
    "    # Kanten generieren (Hier wird sichergestellt, dass alle echten IDs verwendet werden)\n",
    "    for step, relations in pattern_structure[\"steps\"].items():\n",
    "        step_real_id = json_to_pattern_map.get(step, step)\n",
    "\n",
    "        # \"used\"-Kanten erstellen\n",
    "        for used in relations.get(\"uses\", []):\n",
    "            used_real_id = json_to_pattern_map.get(used, used)\n",
    "            if used_real_id and step_real_id:\n",
    "                edges.append((used_real_id, step_real_id))\n",
    "\n",
    "        # \"output\"-Kanten erstellen\n",
    "        for output in relations.get(\"outputs\", []):\n",
    "            output_real_id = json_to_pattern_map.get(output, output)\n",
    "            if output_real_id and step_real_id:\n",
    "                edges.append((step_real_id, output_real_id))\n",
    "\n",
    "    display(f\"\\nâœ… Final Edge List: {edges}\")\n",
    "\n",
    "    # PrÃ¼fen auf unverbundene Knoten\n",
    "    all_edge_nodes = {node for edge in edges for node in edge}\n",
    "    unlinked_nodes = set(json_to_pattern_map.values()) - all_edge_nodes\n",
    "    if unlinked_nodes:\n",
    "        display(f\"âš ï¸ WARNING: Nodes in mapping but not used in edges: {unlinked_nodes}\")\n",
    "\n",
    "    # Ausgabe der components-Struktur\n",
    "    display(\"\\nğŸ§© Components Struktur:\")\n",
    "    display(components)\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "def assign_ranks_with_limited_correction(components, edges):\n",
    "    print(\"ğŸ”§ Starte Topological Rank Assignment mit begrenzter Korrektur (nur bei Knoten ohne VorgÃ¤nger)...\\n\")\n",
    "\n",
    "    # Schritt 1: Graph konstruieren\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    if not nx.is_directed_acyclic_graph(G):\n",
    "        print(\"âŒ Fehler: Der Graph enthÃ¤lt einen Zyklus.\")\n",
    "        return None\n",
    "\n",
    "    topo_order = list(nx.topological_sort(G))\n",
    "\n",
    "    # Schritt 2: Initiale Rangzuweisung\n",
    "    rank_map = {}\n",
    "    for node in topo_order:\n",
    "        preds = list(G.predecessors(node))\n",
    "\n",
    "        if not preds:\n",
    "            rank_map[node] = 0\n",
    "        else:\n",
    "            rank_map[node] = max(rank_map[p] + 1 for p in preds)\n",
    "\n",
    "    print(\"ğŸ¯ VorlÃ¤ufige RÃ¤nge:\")\n",
    "    for node, rank in rank_map.items():\n",
    "        print(f\"  {node}: Rang {rank}\")\n",
    "\n",
    "    # Schritt 3: Korrektur nur fÃ¼r Knoten ohne VorgÃ¤nger\n",
    "    print(\"\\nğŸ” Starte begrenzte Shared-Input-Korrektur fÃ¼r Knoten ohne VorgÃ¤nger...\")\n",
    "    \n",
    "    all_targets = defaultdict(list)\n",
    "    for source, target in edges:\n",
    "        all_targets[source].append(target)\n",
    "\n",
    "    for node, targets in all_targets.items():\n",
    "        if list(G.predecessors(node)):  # Skip nodes with predecessors\n",
    "            continue\n",
    "\n",
    "        candidate_ranks = []\n",
    "        for target in targets:\n",
    "            target_rank = rank_map.get(target, 1)\n",
    "            candidate_ranks.append(target_rank - 1)\n",
    "\n",
    "        if candidate_ranks:\n",
    "            new_rank = min(candidate_ranks)\n",
    "            if new_rank >= 0 and new_rank != rank_map[node]:\n",
    "                print(f\"  ğŸ” Korrektur: {node} von Rang {rank_map[node]} â†’ {new_rank} (basierend auf {len(candidate_ranks)} Targets)\")\n",
    "                rank_map[node] = new_rank\n",
    "\n",
    "    # Schritt 4: Gruppierung nach RÃ¤ngen\n",
    "    grouped = defaultdict(list)\n",
    "    for node, rank in rank_map.items():\n",
    "        grouped[rank].append(node)\n",
    "\n",
    "    print(\"\\nğŸ“Š Final zugewiesene RÃ¤nge nach Korrektur:\")\n",
    "    for rank in sorted(grouped):\n",
    "        print(f\"  Rang {rank}: {grouped[rank]}\")\n",
    "\n",
    "    return rank_map\n",
    "\n",
    "\n",
    "# âœ… Funktion zur Anwendung des Positionsalgorithmus fÃ¼r die FÃ¤lle ohne Template-Auswahl\n",
    "def apply_positioning_algorithm():\n",
    "    # ZunÃ¤chst sicherstellen, dass Component Mapping und Edge Mapping abgeschlossen sind\n",
    "    if components and edges:\n",
    "        print(\"ğŸ”§ Rangzuweisung fÃ¼r das Workflow XML starten...\")\n",
    "        rank_map = assign_ranks_with_limited_correction(components, edges)\n",
    "        \n",
    "        if rank_map:\n",
    "            print(\"\\nâœ… Rangzuweisung erfolgreich durchgefÃ¼hrt.\")\n",
    "            return rank_map\n",
    "        else:\n",
    "            print(\"âŒ Rangzuweisung fehlgeschlagen.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"âš ï¸ Bitte sicherstellen, dass alle Komponenten und Kanten vor der Rangzuweisung definiert sind.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Funktion zur ID-Deduplizierung ===\n",
    "def deduplicate_ids(variables):\n",
    "    seen_ids = {}\n",
    "    updated_variables = {}\n",
    "\n",
    "    for key, var in variables.items():\n",
    "        original_id = var[\"id\"]\n",
    "        label = var.get(\"label\", \"\")\n",
    "\n",
    "        if original_id in seen_ids:\n",
    "            seen_ids[original_id] += 1\n",
    "            new_id = f\"{original_id}_{seen_ids[original_id]}\"\n",
    "        else:\n",
    "            seen_ids[original_id] = 1\n",
    "            new_id = original_id\n",
    "\n",
    "        updated_variables[key] = {\n",
    "            \"id\": new_id,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "    return updated_variables\n",
    "\n",
    "# === JSON-Datei einlesen und Variablen setzen ===\n",
    "def load_instance_json(json_filename):\n",
    "    global instance_data, pattern\n",
    "\n",
    "    try:\n",
    "        with open(json_filename, \"r\") as json_file:\n",
    "            extracted_data = json.load(json_file)\n",
    "            instance_data = extracted_data\n",
    "\n",
    "        # System-Label und Pattern-URI extrahieren\n",
    "        system_label = instance_data.get(\"metadata\", {}).get(\"label\", \"no label\")\n",
    "        raw_pattern_uri = instance_data.get(\"relationships\", {}).get(\"hasCorrespondingPattern\", [None])[0]\n",
    "\n",
    "        # Sicher extrahieren â€“ falls kein Pattern vorhanden, als \"no pattern\" setzen\n",
    "        if raw_pattern_uri:\n",
    "            pattern = raw_pattern_uri.split(\".\")[-1] if \"Pattern.\" in raw_pattern_uri else raw_pattern_uri.split(\"/\")[-1]\n",
    "        else:\n",
    "            pattern = \"no pattern\"\n",
    "\n",
    "        pattern_info = f\"ğŸ§© Pattern detected: {pattern}\" if pattern != \"no pattern\" else \"âš ï¸ No pattern detected\"\n",
    "\n",
    "        # IDs deduplizieren\n",
    "        instance_data[\"variables\"] = deduplicate_ids(instance_data.get(\"variables\", {}))\n",
    "\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"âœ… Loaded instance: {system_label}\")\n",
    "            print(f\"ğŸ“ raw_pattern_uri: {raw_pattern_uri}\")\n",
    "            print(f\"ğŸ§© pattern: {pattern}\")\n",
    "            print(pattern_info)\n",
    "\n",
    "        # Danach weitere Pattern-Entscheidung anzeigen\n",
    "        handle_pattern_selection()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"âŒ JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"âŒ Error loading JSON:\\nâ†’ {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"âŒ JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"âŒ Error loading JSON:\\nâ†’ {e}\")\n",
    "\n",
    "# === Button zur AusfÃ¼hrung ===\n",
    "load_button = widgets.Button(description=\"Load Extracted JSON\", button_style=\"primary\")\n",
    "def on_load_click(b):\n",
    "    try:\n",
    "        json_file = f\"{selected_system_id}.json\"\n",
    "        load_instance_json(json_file)\n",
    "    except NameError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"âŒ No system selected. Please extract a system first.\")\n",
    "\n",
    "load_button.on_click(on_load_click)\n",
    "\n",
    "\n",
    "display(load_button, pattern_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from rdflib import Graph, Namespace, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# === Globals for reuse ===\n",
    "pattern_structure = None\n",
    "pattern_choice = None\n",
    "pattern_graph = None\n",
    "pattern = None\n",
    "\n",
    "# === Variables from previous steps assumed ===\n",
    "# instance_data (dict), pattern (str or \"no pattern\")\n",
    "\n",
    "# === Output containers ===\n",
    "pattern_upload_output = widgets.Output()\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description=\"â¬‡ï¸ Download Template XML\",\n",
    "    button_style=\"info\",\n",
    "    icon=\"download\"\n",
    ")\n",
    "download_output = widgets.Output()\n",
    "\n",
    "\n",
    "pattern_continue_button = widgets.Button(\n",
    "    description=\"Continue with uploaded pattern\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "# === Upload widget (only shown when needed) ===\n",
    "pattern_upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload Pattern File'\n",
    ")\n",
    "\n",
    "# === Pattern decision: Template or Generate ===\n",
    "pattern_choice_selector = widgets.ToggleButtons(\n",
    "    options=[\n",
    "        (\"Use template\", \"template\"),\n",
    "        (\"Generate automatically\", \"generate\")\n",
    "    ],\n",
    "    description=\"Select Pattern Option:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "# âœ… Template generieren und Download-Button anzeigen\n",
    "def generate_template_from_instance():\n",
    "    print(\"ğŸ›  generate_template_from_instance() aufgerufen\")\n",
    "    global pattern, instance_data, pattern_structure\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” Aktuelles Pattern: {pattern}\")\n",
    "        print(f\"ğŸ“¦ instance_data vorhanden: {'instance_data' in globals()}\")\n",
    "        print(f\"ğŸ“¦ pattern_structure vorhanden: {'pattern_structure' in globals()}\")\n",
    "\n",
    "        if not pattern or pattern in (\"no pattern\", \"None\", None):\n",
    "            print(\"âš ï¸ Kein gÃ¼ltiges Pattern gesetzt. Abbruch.\")\n",
    "            return\n",
    "\n",
    "        template_path = f\"Templates/{pattern}.xml\"\n",
    "        print(f\"ğŸ“„ Template-Pfad: {template_path}\")\n",
    "\n",
    "        if not os.path.exists(template_path):\n",
    "            print(f\"âŒ Template-Datei nicht gefunden: {template_path}\")\n",
    "            return\n",
    "\n",
    "        with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            xml_template = f.read()\n",
    "            print(\"âœ… Template-Datei geladen\")\n",
    "\n",
    "        updated_xml = replace_pattern_placeholders(xml_template, instance_data, pattern_structure)\n",
    "        print(\"âœ… XML erfolgreich ersetzt\")\n",
    "\n",
    "        # Mapping-Name z.â€¯B. nach Instanz-ID setzen\n",
    "        instance_id = instance_data.get(\"id\", \"unknown\")\n",
    "        output_path = f\"Updated_{instance_id}_Workflow.xml\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(updated_xml)\n",
    "\n",
    "        print(f\"âœ… Template erfolgreich generiert: {output_path}\")\n",
    "\n",
    "        with download_output:\n",
    "            download_output.clear_output()\n",
    "            file_dl = FileDownload(\n",
    "                data=updated_xml,\n",
    "                filename=output_path,\n",
    "                description=\"â¬‡ï¸ Download XML\",\n",
    "                button_style=\"success\"\n",
    "            )\n",
    "            display(file_dl)\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"âŒ Fehler beim Generieren des Templates:\")\n",
    "        traceback.print_exception(type(e), e, e.__traceback__)\n",
    "\n",
    "def handle_pattern_selection():\n",
    "    global pattern, pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "    pattern_upload_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        with pattern_output:\n",
    "            print(f\"ğŸ” DEBUG pattern: {pattern}\")\n",
    "\n",
    "            if pattern is None or pattern == \"no pattern\":\n",
    "                print(\"ğŸ“‚ No pattern linked to system. Please upload a pattern TTL file.\")\n",
    "                display(pattern_upload_widget)\n",
    "                display(pattern_continue_button)\n",
    "                display(pattern_upload_output)\n",
    "            else:\n",
    "                print(f\"ğŸ§© Pattern detected: {pattern}\")\n",
    "                print(\"How would you like to proceed?\")\n",
    "                display(pattern_choice_selector)\n",
    "\n",
    "                # â—ï¸WICHTIG: Button fÃ¼r Fortfahren zeigen\n",
    "                display(pattern_decision_continue_button)\n",
    "                pattern_decision_continue_button.layout.display = \"inline-block\"\n",
    "\n",
    "                # ğŸ†• Pattern-Choice merken\n",
    "                pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    except Exception as e:\n",
    "        show_exception(e)\n",
    "\n",
    "\n",
    "        \n",
    "from collections import defaultdict\n",
    "\n",
    "# Output-Widget fÃ¼r die Plots\n",
    "plot_output = widgets.Output()\n",
    "\n",
    "def on_pattern_decision_continue(b):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        print(\"â¡ï¸ Continue decision clicked\")\n",
    "        print(f\"ğŸ§­ Selected option: {pattern_choice}\")\n",
    "\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        elif pattern_choice in [\"generate\", \"upload\"]:\n",
    "            run_component_mapping()\n",
    "            rank_map = apply_positioning_algorithm()\n",
    "\n",
    "            if rank_map:\n",
    "                unordered_layers = defaultdict(list)\n",
    "                for node, rank in rank_map.items():\n",
    "                    unordered_layers[rank].append(node)\n",
    "\n",
    "                ordered_layers = apply_median_heuristic(rank_map, edges, sort_layer_0=True)\n",
    "\n",
    "                # ğŸ“Š Plotten im Widget\n",
    "                plot_output.clear_output()\n",
    "                with plot_output:\n",
    "                    plot_graph_layout(edges, rank_map, unordered_layers, title=\"Ungeordnete Reihenfolge innerhalb der Layer\")\n",
    "                    plot_graph_layout(edges, rank_map, ordered_layers, title=\"Mit Median-Heuristik geordnete Layer\")\n",
    "\n",
    "        else:\n",
    "            print(\"âš ï¸ Keine gÃ¼ltige Option gewÃ¤hlt.\")\n",
    "\n",
    "    pattern_decision_continue_button.layout.display = \"none\"\n",
    "\n",
    "# Button registrieren\n",
    "pattern_decision_continue_button.on_click(on_pattern_decision_continue)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Extract logic from TTL file ===\n",
    "def extract_pattern_structure_from_file(file_path):\n",
    "    g = Graph()\n",
    "    g.parse(file_path, format=\"turtle\")\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology/\")\n",
    "    RES = Namespace(\"http://semantic-systems.net/swemls/\")\n",
    "\n",
    "    def clean_uri(uri):\n",
    "        label = uri.split(\"/\")[-1].split(\"#\")[-1]\n",
    "        label = re.sub(r'Pattern\\.[A-Za-z0-9]+\\.', '', label)\n",
    "        label = re.sub(r'^[A-Za-z0-9]+\\.', '', label)\n",
    "        return label\n",
    "\n",
    "    structure = {\"steps\": {}, \"variables\": {}}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    return structure\n",
    "\n",
    "# === Trigger on pattern upload ===\n",
    "def on_pattern_upload(change):\n",
    "    global pattern_structure\n",
    "\n",
    "    if not pattern_upload_widget.value:\n",
    "        return\n",
    "\n",
    "    uploaded = next(iter(pattern_upload_widget.value.items()))  # (filename, fileinfo)\n",
    "    file_name = uploaded[0]\n",
    "    file_content = uploaded[1]['content']\n",
    "\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(file_content)\n",
    "\n",
    "    with pattern_output:\n",
    "        clear_output()\n",
    "        print(f\"âœ… Pattern file uploaded: {file_name}\")\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_name)\n",
    "        with pattern_output:\n",
    "            print(\"âœ… Extracted pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"âŒ Error parsing pattern file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pattern_upload_widget.observe(on_pattern_upload, names='value')\n",
    "\n",
    "\n",
    "\n",
    "def on_pattern_choice(change):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = change['new']\n",
    "    file_path = f\"Patterns/{pattern}-pattern.ttl\"\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_path)\n",
    "\n",
    "        with pattern_output:\n",
    "            print(f\"âœ… Pattern '{pattern}' loaded from: {file_path}\")\n",
    "            print(f\"ğŸ§© Pattern mode selected: {pattern_choice}\")\n",
    "            print(\"ğŸ“Š Pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "\n",
    "        # â¬…ï¸ Template ausfÃ¼hren, wenn Template gewÃ¤hlt wurde\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        # ğŸ†• Wenn nicht Template, Button wieder anzeigen!\n",
    "        if pattern_choice in [\"generate\", \"upload\"]:\n",
    "            pattern_decision_continue_button.layout.display = \"inline-block\"\n",
    "            display(pattern_decision_continue_button)\n",
    "\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"âŒ Error reading pattern file: {file_path}\")\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "pattern_choice_selector.observe(on_pattern_choice, names='value')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "main_pattern_box = widgets.VBox([\n",
    "    pattern_output,\n",
    "    pattern_upload_output,\n",
    "    download_output  # ğŸ†• Zeigt den Download-Link nach Template-Erstellung\n",
    "])\n",
    "\n",
    "\n",
    "# Button-Handler aktivieren â¬‡ï¸\n",
    "pattern_continue_button.on_click(on_pattern_continue)\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "handle_pattern_selection()\n",
    "display(main_pattern_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import os\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# === Globale Ausgabe-Widgets ===\n",
    "download_output = widgets.Output()\n",
    "\n",
    "# === Funktion zur Fehlerausgabe ===\n",
    "def show_exception(e):\n",
    "    print(\"âŒ Exception caught:\")\n",
    "    traceback.print_exception(type(e), e, e.__traceback__, file=sys.stdout)\n",
    "\n",
    "# === Funktion zum Extrahieren des Labels aus einem Schritt ===\n",
    "def extract_label_short(step):\n",
    "    labels = step.get(\"metadata\", {}).get(\"label\", [])\n",
    "    if labels:\n",
    "        match = re.search(r\"\\((.*?)\\)\", labels[0])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return step[\"id\"].split(\".\")[-1]\n",
    "\n",
    "# === Funktion zum Ersetzen der Platzhalter im XML ===\n",
    "def replace_pattern_placeholders(xml_string, instance_data, pattern_structure):\n",
    "    with download_output:\n",
    "        print(\"\\U0001f527 replace_pattern_placeholders() aufgerufen\")\n",
    "        print(f\"\\U0001f527 XML LÃ¤nge: {len(xml_string)}\")\n",
    "        print(f\"\\U0001f527 Instance data keys: {list(instance_data.keys())}\")\n",
    "        print(f\"\\U0001f527 Pattern structure keys: {list(pattern_structure.keys())}\")\n",
    "\n",
    "    tree = ET.ElementTree(ET.fromstring(xml_string))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    replacements = {}\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\U0001f501 Schritte werden ersetzt...\")\n",
    "    for step in instance_data.get(\"steps\", []):\n",
    "        step_key = step[\"id\"].split(\".\")[-1]\n",
    "        step_label = extract_label_short(step)\n",
    "        replacements[step_key] = step_label\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\U0001f501 Variablen werden ersetzt...\")\n",
    "    for pattern_var in pattern_structure.get(\"variables\", {}):\n",
    "        for var_key, var_data in instance_data.get(\"variables\", {}).items():\n",
    "            if pattern_var.lower() in var_key.lower():\n",
    "                inst_id = var_data[\"id\"].replace(\"Resource.\", \"\").replace(\"Custom.\", \"\")\n",
    "                replacements[pattern_var] = inst_id\n",
    "                break\n",
    "\n",
    "    with download_output:\n",
    "        print(\"\\n\\U0001f9e9 Mapping for replacements:\")\n",
    "        for k, v in replacements.items():\n",
    "            print(f\"  {k} â†’ {v}\")\n",
    "\n",
    "    for element in root.iter(\"mxCell\"):\n",
    "        if 'value' in element.attrib:\n",
    "            value = element.attrib['value']\n",
    "            for placeholder, real_value in replacements.items():\n",
    "                if placeholder in value:\n",
    "                    replacement = real_value.replace(\"_\", \" \") if real_value.strip() else \"Missing\"\n",
    "                    style = element.attrib.get(\"style\", \"\")\n",
    "                    length = len(replacement)\n",
    "                    if length > 24:\n",
    "                        style += \";fontSize=5\"\n",
    "                    elif length > 20:\n",
    "                        style += \";fontSize=7\"\n",
    "                    elif length > 17:\n",
    "                        style += \";fontSize=9\"\n",
    "                    element.attrib['style'] = style\n",
    "                    element.attrib['value'] = value.replace(placeholder, replacement)\n",
    "\n",
    "    return ET.tostring(root, encoding='utf-8', method='xml').decode()\n",
    "\n",
    "# === Template generieren und Base64-Download-Link anzeigen ===\n",
    "def generate_template_from_instance():\n",
    "    global pattern, instance_data, pattern_structure\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        try:\n",
    "            print(\"\\U0001f6e0 generate_template_from_instance() aufgerufen\")\n",
    "            print(f\"\\U0001f50d Aktuelles Pattern: {pattern}\")\n",
    "            print(f\"\\U0001f4e6 instance_data vorhanden: {'instance_data' in globals()}\")\n",
    "            print(f\"\\U0001f4e6 pattern_structure vorhanden: {pattern_structure is not None}\")\n",
    "\n",
    "            if not pattern or pattern in (\"no pattern\", \"None\", None):\n",
    "                print(\"âš ï¸ Kein gÃ¼ltiges Pattern gesetzt. Abbruch.\")\n",
    "                return\n",
    "\n",
    "            template_path = f\"Templates/{pattern}.xml\"\n",
    "            print(f\"\\U0001f4c4 Template-Pfad: {template_path}\")\n",
    "\n",
    "            if not os.path.exists(template_path):\n",
    "                print(f\"âŒ Template-Datei nicht gefunden: {template_path}\")\n",
    "                return\n",
    "\n",
    "            with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                xml_template = f.read()\n",
    "                print(f\"âœ… Template-Datei geladen mit LÃ¤nge {len(xml_template)}\")\n",
    "\n",
    "            updated_xml = replace_pattern_placeholders(xml_template, instance_data, pattern_structure)\n",
    "            print(\"âœ… XML erfolgreich ersetzt\")\n",
    "\n",
    "            instance_id = instance_data.get(\"id\", \"unknown\")\n",
    "            filename = f\"Updated_{instance_id}_Workflow.xml\"\n",
    "\n",
    "            # Base64 codieren und HTML-Link erstellen\n",
    "            b64 = base64.b64encode(updated_xml.encode()).decode()\n",
    "            href = f'data:application/xml;base64,{b64}'\n",
    "            display(HTML(f'<a download=\"{filename}\" href=\"{href}\" target=\"_blank\">â¬‡ï¸ Click here to download the XML file</a>'))\n",
    "            print(f\"âœ… Datei bereit: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"âŒ Fehler beim Generieren des Templates:\")\n",
    "            traceback.print_exception(type(e), e, e.__traceback__)\n",
    "\n",
    "# ğŸ†• Entscheidung durchfÃ¼hren Button\n",
    "pattern_decision_continue_button = widgets.Button(\n",
    "    description=\"Continue with selected option\",\n",
    "    button_style=\"primary\",\n",
    "    icon=\"check\"\n",
    ")\n",
    "\n",
    "def on_pattern_decision_continue(b):\n",
    "    global pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_choice = pattern_choice_selector.value\n",
    "\n",
    "    # ğŸ§  Absicherung: Wenn noch kein pattern_structure geladen, dann jetzt laden\n",
    "    if pattern_structure is None and pattern and pattern_choice == \"template\":\n",
    "        try:\n",
    "            file_path = f\"Patterns/{pattern}-pattern.ttl\"\n",
    "            pattern_structure = extract_pattern_structure_from_file(file_path)\n",
    "            print(f\"âœ… Pattern structure nachgeladen aus: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Fehler beim Nachladen der Patternstruktur: {e}\")\n",
    "            return\n",
    "\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        print(\"â¡ï¸ Continue decision clicked\")\n",
    "        print(f\"ğŸ§­ Selected option: {pattern_choice}\")\n",
    "\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "        elif pattern_choice in [\"generate\", \"upload\"]:\n",
    "            run_component_mapping()\n",
    "            rank_map = apply_positioning_algorithm()\n",
    "\n",
    "            # âœ… Visualisierung starten, wenn Rangzuweisung erfolgreich war\n",
    "            if rank_map:\n",
    "                unordered_layers = defaultdict(list)\n",
    "                for node, rank in rank_map.items():\n",
    "                    unordered_layers[rank].append(node)\n",
    "\n",
    "                ordered_layers = apply_median_heuristic(rank_map, edges, sort_layer_0=True)\n",
    "\n",
    "                plot_output.clear_output()\n",
    "                with plot_output:\n",
    "                    print(\"ğŸ“Š Visualisierung der Workflows:\")\n",
    "                    plot_graph_layout(edges, rank_map, unordered_layers, title=\"Ungeordnete Reihenfolge innerhalb der Layer\")\n",
    "                    plot_graph_layout(edges, rank_map, ordered_layers, title=\"Mit Median-Heuristik geordnete Layer\")\n",
    "\n",
    "                display(plot_output)\n",
    "            else:\n",
    "                with plot_output:\n",
    "                    print(\"âš ï¸ Rangberechnung fehlgeschlagen â€“ keine Visualisierung mÃ¶glich.\")\n",
    "                display(plot_output)\n",
    "\n",
    "        else:\n",
    "            print(\"âš ï¸ Keine gÃ¼ltige Option gewÃ¤hlt.\")\n",
    "\n",
    "    pattern_decision_continue_button.layout.display = \"none\"\n",
    "\n",
    "\n",
    "pattern_decision_continue_button.on_click(on_pattern_decision_continue)\n",
    "\n",
    "# ğŸ†• Anzeige des Buttons und Ausgabecontainers\n",
    "display(pattern_decision_continue_button, download_output)\n",
    "\n",
    "# âœ… Anzeigen im Notebook\n",
    "display(component_mapping_output, edge_mapping_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_crossings(layers: Dict[int, List[str]], edges: List[Tuple[str, str]]) -> int:\n",
    "    pos_in_layer = {node: (rank, i) for rank, nodes in layers.items() for i, node in enumerate(nodes)}\n",
    "    crossings = 0\n",
    "    for (u1, v1), (u2, v2) in itertools.combinations(edges, 2):\n",
    "        if u1 not in pos_in_layer or v1 not in pos_in_layer or u2 not in pos_in_layer or v2 not in pos_in_layer:\n",
    "            continue\n",
    "        r1_u, x1_u = pos_in_layer[u1]\n",
    "        r1_v, x1_v = pos_in_layer[v1]\n",
    "        r2_u, x2_u = pos_in_layer[u2]\n",
    "        r2_v, x2_v = pos_in_layer[v2]\n",
    "        if r1_v != r2_v:\n",
    "            continue  # Only compare edges in the same layer\n",
    "        if (x1_u - x2_u) * (x1_v - x2_v) < 0:\n",
    "            crossings += 1\n",
    "    return crossings\n",
    "\n",
    "def greedy_swap_optimization(layers: Dict[int, List[str]], edges: List[Tuple[str, str]], iterations: int = 10) -> Dict[int, List[str]]:\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    new_layers = {r: list(nodes) for r, nodes in layers.items()}  # Copy\n",
    "    print(\"\\nğŸ” Starte Greedy-Swap Optimierung...\\n\")\n",
    "    for r in sorted(new_layers):\n",
    "        if r == 0:\n",
    "            continue  # Don't optimize layer 0\n",
    "        improved = True\n",
    "        while improved:\n",
    "            improved = False\n",
    "            current = new_layers[r]\n",
    "            for i in range(len(current) - 1):\n",
    "                swapped = list(current)\n",
    "                swapped[i], swapped[i+1] = swapped[i+1], swapped[i]\n",
    "                temp_layers = dict(new_layers)\n",
    "                temp_layers[r] = swapped\n",
    "                old_crossings = count_crossings(new_layers, edges)\n",
    "                new_crossings = count_crossings(temp_layers, edges)\n",
    "                if new_crossings < old_crossings:\n",
    "                    print(f\"  âœ… Swap: {current[i]} â¬Œ {current[i+1]} reduziert Kreuzungen: {old_crossings} â†’ {new_crossings}\")\n",
    "                    new_layers[r] = swapped\n",
    "                    improved = True\n",
    "                    break\n",
    "    return new_layers\n",
    "\n",
    "def apply_median_heuristic(rank_map: Dict[str, int], edges: List[Tuple[str, str]], sort_layer_0: bool = False) -> Dict[int, List[str]]:\n",
    "    print(\"\\nğŸ”§ Starte Median-Heuristik zur Anordnung der Knoten innerhalb von RÃ¤ngen...\\n\")\n",
    "    layers = defaultdict(list)\n",
    "    for node, rank in rank_map.items():\n",
    "        layers[rank].append(node)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    ordered_layers = {}\n",
    "    for r in sorted(layers.keys()):\n",
    "        if r == 0 and not sort_layer_0:\n",
    "            ordered_layers[r] = layers[r]\n",
    "            continue\n",
    "        def median(node):\n",
    "            preds = list(G.predecessors(node))\n",
    "            if not preds:\n",
    "                return float('inf')\n",
    "            return sum([layers[rank_map[pred]].index(pred) for pred in preds if pred in layers[rank_map[pred]]]) / len(preds)\n",
    "        sorted_nodes = sorted(layers[r], key=median)\n",
    "        ordered_layers[r] = sorted_nodes\n",
    "    print(\"ğŸ“Š Ergebnis der Median-Heuristik:\")\n",
    "    for rank in sorted(ordered_layers):\n",
    "        print(f\"  Rang {rank}: {ordered_layers[rank]}\")\n",
    "    return ordered_layers\n",
    "\n",
    "def plot_graph_layout(edges: List[Tuple[str, str]], rank_map: Dict[str, int], layer_nodes: Dict[int, List[str]], title: str = \"Graph Layout\") -> None:\n",
    "    pos = {}\n",
    "    x_spacing = 2\n",
    "    y_spacing = 2\n",
    "    for r, nodes in sorted(layer_nodes.items()):\n",
    "        for i, node in enumerate(nodes):\n",
    "            pos[node] = (i * x_spacing, -r * y_spacing)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=8, arrows=True)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# Am Ende des Notebooks:\n",
    "display(plot_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
