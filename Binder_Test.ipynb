{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "\n",
    "def show_exception(e):\n",
    "    print(\"‚ùå Exception caught:\")\n",
    "    traceback.print_exception(type(e), e, e.__traceback__, file=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rdflib import Graph, Namespace\n",
    "import ipywidgets as widgets\n",
    "\n",
    "shacl_output = widgets.Output()\n",
    "\n",
    "# === SHACL-Regeln anwenden auf hochgeladene Datei ===\n",
    "def apply_shacl_rules(instance_file_path: str) -> Graph:\n",
    "    SH = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    shapes_dir = \"Shapes\"  # relative Pfadangabe im Repo\n",
    "\n",
    "    shape_files = [\n",
    "        \"_generic-shapes.ttl\", \"A1-shapes.ttl\", \"A2-shapes.ttl\", \"A3-shapes.ttl\",\n",
    "        \"F1-shapes.ttl\", \"F2-shapes.ttl\", \"F3-shapes.ttl\", \"F4-shapes.ttl\",\n",
    "        \"I1-shapes.ttl\", \"I2-shapes.ttl\", \"I3-shapes.ttl\", \"I4-shapes.ttl\",\n",
    "        \"I5-shapes.ttl\", \"I6-shapes.ttl\", \"I7-shapes.ttl\", \"O1-shapes.ttl\",\n",
    "        \"O2-shapes.ttl\", \"O3-shapes.ttl\", \"O4-shapes.ttl\", \"T1-shapes.ttl\",\n",
    "        \"T2-shapes.ttl\", \"T3-shapes.ttl\", \"T4-shapes.ttl\", \"T5-shapes.ttl\",\n",
    "        \"T6-shapes.ttl\", \"T7-shapes.ttl\", \"T8-shapes.ttl\", \"T9-shapes.ttl\",\n",
    "        \"T10-shapes.ttl\", \"T11-shapes.ttl\", \"T12-shapes.ttl\", \"T13-shapes.ttl\",\n",
    "        \"T14-shapes.ttl\", \"T15-shapes.ttl\", \"T16-shapes.ttl\", \"T17-shapes.ttl\",\n",
    "        \"T18-shapes.ttl\", \"T19-shapes.ttl\", \"T20-shapes.ttl\", \"T21-shapes.ttl\",\n",
    "        \"T22-shapes.ttl\", \"T23-shapes.ttl\", \"Y1-shapes.ttl\", \"Y2-shapes.ttl\", \"Y4-shapes.ttl\"\n",
    "    ]\n",
    "\n",
    "    g_instance = Graph()\n",
    "    g_instance.parse(instance_file_path, format=\"turtle\")\n",
    "\n",
    "    triples_before = len(g_instance)\n",
    "\n",
    "    for shape_file in shape_files:\n",
    "        shape_path = os.path.join(shapes_dir, shape_file)\n",
    "        g_shape = Graph()\n",
    "\n",
    "        if not os.path.exists(shape_path):\n",
    "            with shacl_output:\n",
    "                print(f\"‚ö†Ô∏è Shape file not found: {shape_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            g_shape.parse(shape_path, format=\"turtle\")\n",
    "            with shacl_output:\n",
    "                print(f\"‚úÖ Loaded SHACL shape file: {shape_file}\")\n",
    "        except Exception as e:\n",
    "            with shacl_output:\n",
    "                print(f\"‚ùå Error loading {shape_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for rule in g_shape.subjects(predicate=SH.rule, object=None):\n",
    "            for _, _, construct_query in g_shape.triples((rule, SH.construct, None)):\n",
    "                query = str(construct_query)\n",
    "                try:\n",
    "                    g_instance.update(query)\n",
    "                except Exception as e:\n",
    "                    with shacl_output:\n",
    "                        print(f\"‚ùå Error executing rule from {shape_file}: {e}\")\n",
    "\n",
    "    triples_after = len(g_instance)\n",
    "    with shacl_output:\n",
    "        print(\"‚úÖ All rules applied.\")\n",
    "        print(f\"üìä Triples before: {triples_before}\")\n",
    "        print(f\"üìà Triples after: {triples_after}\")\n",
    "        print(f\"‚ûï Added: {triples_after - triples_before} triples\")\n",
    "\n",
    "    return g_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from rdflib import Graph\n",
    "\n",
    "# === Globale Variablen ===\n",
    "instance_file_path = None\n",
    "output = widgets.Output()\n",
    "result_graph = None\n",
    "\n",
    "\n",
    "\n",
    "# === Auswahlfeld: Beispiel oder Upload ===\n",
    "option_selector = widgets.ToggleButtons(\n",
    "    options=[(\"Use example file\", \"example\"), (\"Upload your own\", \"upload\")],\n",
    "    description=\"Select input:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# === Upload-Widget (immer sichtbar) ===\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload TTL file'\n",
    ")\n",
    "\n",
    "# === \"Continue\"-Button ===\n",
    "continue_button = widgets.Button(description=\"Continue\", button_style='primary')\n",
    "\n",
    "# === Auswahlhandler ===\n",
    "def on_option_change(change):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        if change['new'] == 'example':\n",
    "            global instance_file_path\n",
    "            instance_file_path = \"Instance_Files/swemls-instances.ttl\"\n",
    "            print(f\"üìÅ Example file selected:\\n‚Üí {instance_file_path}\")\n",
    "        elif change['new'] == 'upload':\n",
    "            print(\"üì§ Please upload a TTL file using the field below.\")\n",
    "\n",
    "option_selector.observe(on_option_change, names='value')\n",
    "\n",
    "# === Upload-Handler ===\n",
    "def on_upload(change):\n",
    "    global instance_file_path\n",
    "    if upload_widget.value:\n",
    "        uploaded = upload_widget.value[0]\n",
    "        file_name = uploaded['name']\n",
    "        instance_file_path = file_name\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(uploaded['content'])\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(f\"‚úÖ File uploaded and saved as:\\n‚Üí {file_name}\")\n",
    "\n",
    "upload_widget.observe(on_upload, names='value')\n",
    "\n",
    "# === Continue-Button-Handler ===\n",
    "def on_continue(b):\n",
    "    global result_graph\n",
    "    output.clear_output()\n",
    "    if not instance_file_path:\n",
    "        with output:\n",
    "            print(\"‚ö†Ô∏è No file selected or uploaded.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(instance_file_path):\n",
    "        with output:\n",
    "            print(f\"‚ùå File not found on disk:\\n‚Üí {instance_file_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if instance_file_path.endswith(\".ttl\") and not instance_file_path.startswith(\"Instance_Files/\"):\n",
    "            with output:\n",
    "                print(\"üîç SHACL rules will be applied to uploaded file.\")\n",
    "            result_graph = apply_shacl_rules(instance_file_path)\n",
    "        else:\n",
    "            g = Graph()\n",
    "            g.parse(instance_file_path, format=\"turtle\")\n",
    "            result_graph = g\n",
    "\n",
    "        with output:\n",
    "            print(f\"‚úÖ RDF file successfully loaded!\")\n",
    "            print(f\"üìÑ Triples in graph: {len(result_graph)}\")\n",
    "            print(f\"üîó Using file:\\n‚Üí {instance_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"‚ùå Error parsing TTL file:\\n‚Üí {e}\")\n",
    "\n",
    "    # ‚¨áÔ∏è SHACL-Ausgabe sichtbar machen\n",
    "    display(shacl_output)\n",
    "\n",
    "continue_button.on_click(on_continue)\n",
    "\n",
    "# === Anzeige aller Elemente ===\n",
    "display(option_selector, upload_widget, continue_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from rdflib.namespace import RDF\n",
    "from IPython.display import display\n",
    "\n",
    "# Outputs\n",
    "query_interface_output = widgets.Output()\n",
    "selection_output = widgets.Output()\n",
    "\n",
    "# SPARQL Query-Feld\n",
    "query_input = widgets.Textarea(\n",
    "    value=\"\"\"\n",
    "PREFIX swemls: <https://w3id.org/semsys/ns/swemls#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?system\n",
    "WHERE {\n",
    "  ?system a swemls:System .\n",
    "  ?system swemls:hasCorrespondingPattern ?pattern .\n",
    "  FILTER(STRENDS(STR(?pattern), \"O1\"))\n",
    "}\n",
    "\"\"\",\n",
    "    placeholder='Enter your SPARQL query here...',\n",
    "    description='SPARQL Query:',\n",
    "    layout=widgets.Layout(width='100%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Buttons\n",
    "run_query_button = widgets.Button(description=\"Run Query\", button_style='primary')\n",
    "confirm_button = widgets.Button(description=\"Confirm selection\", button_style='success')\n",
    "\n",
    "# Dropdown f√ºr Systeme\n",
    "system_selector = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description=\"Select system:\",\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Globales Ergebnis\n",
    "matched_systems = []\n",
    "\n",
    "# Query-Handler\n",
    "def on_query_run(b):\n",
    "    global matched_systems\n",
    "    query_interface_output.clear_output()\n",
    "    selection_output.clear_output()\n",
    "    system_selector.options = []\n",
    "\n",
    "    if 'result_graph' not in globals() or result_graph is None:\n",
    "        with query_interface_output:\n",
    "            print(\"‚ö†Ô∏è RDF graph not loaded.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        results = result_graph.query(query_input.value)\n",
    "    except Exception as e:\n",
    "        with query_interface_output:\n",
    "            print(f\"‚ùå Query error: {e}\")\n",
    "        return\n",
    "\n",
    "    matched_systems = []\n",
    "    for row in results:\n",
    "        uri = str(row.system)\n",
    "        sys_id = uri.split(\"/\")[-1]\n",
    "        matched_systems.append((sys_id, uri))\n",
    "\n",
    "    if not matched_systems:\n",
    "        with query_interface_output:\n",
    "            print(\"‚ö†Ô∏è No matching systems found.\")\n",
    "        return\n",
    "\n",
    "    system_selector.options = [(sys_id, uri) for sys_id, uri in matched_systems]\n",
    "\n",
    "    with query_interface_output:\n",
    "        print(f\"‚úÖ Found {len(matched_systems)} matching system(s):\")\n",
    "        for i, (sys_id, _) in enumerate(matched_systems):\n",
    "            print(f\" {i+1}: {sys_id}\")\n",
    "\n",
    "# Auswahl-Handler\n",
    "def on_confirm_selection(b):\n",
    "    global selected_system_id, selected_system_uri\n",
    "    selected_label = system_selector.label\n",
    "    selected_uri = system_selector.value\n",
    "    selected_system_id = selected_label\n",
    "    selected_system_uri = selected_uri\n",
    "    with selection_output:\n",
    "        selection_output.clear_output()\n",
    "        print(f\"‚úÖ You selected: {selected_system_id}\")\n",
    "        print(f\"üîó URI: {selected_system_uri}\")\n",
    "\n",
    "# Event-Bindings\n",
    "run_query_button.on_click(on_query_run)\n",
    "confirm_button.on_click(on_confirm_selection)\n",
    "\n",
    "# Anzeigen\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        query_input,\n",
    "        run_query_button,\n",
    "        query_interface_output,\n",
    "        widgets.HBox([system_selector, confirm_button]),\n",
    "        selection_output\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "json_output = widgets.Output()\n",
    "\n",
    "def extract_and_export_selected_system():\n",
    "    global selected_system_id, selected_system_uri, result_graph\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology#\")\n",
    "    RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "    rdf_type = URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\")\n",
    "    ai_system_type = SWEMLS.System\n",
    "    documentation_type = SWEMLS.Documentation\n",
    "    paper_type = SWEMLS.Paper\n",
    "    ml_component_type = SWEMLS.MachineLearningComponent\n",
    "    kr_component_type = SWEMLS.KnowledgeRepresentationComponent\n",
    "    data_type = SWEMLS.Data\n",
    "    semantic_web_resource_type = SWEMLS.SemanticWebResource\n",
    "    has_documentation = SWEMLS.hasDocumentation\n",
    "    reports_on = SWEMLS.reports\n",
    "    rdfs_label = RDFS.label\n",
    "\n",
    "    g = result_graph\n",
    "\n",
    "    # 1. System und zugeh√∂rige Paper finden\n",
    "    ai_systems = [\n",
    "        system for system in g.subjects(RDF.type, ai_system_type)\n",
    "        if str(system).split(\"/\")[-1] == selected_system_id\n",
    "    ]\n",
    "\n",
    "    system_to_paper = {}\n",
    "    for paper in g.subjects(predicate=rdf_type, object=paper_type):\n",
    "        for reported_system in g.objects(subject=paper, predicate=reports_on):\n",
    "            system_id = str(reported_system).split(\"/\")[-1]\n",
    "            paper_id = str(paper).split(\"/\")[-1]\n",
    "            paper_metadata = {\"id\": paper_id, \"metadata\": {}}\n",
    "            for pred, obj in g.predicate_objects(subject=paper):\n",
    "                pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "                paper_metadata[\"metadata\"].setdefault(pred_name, []).append(str(obj))\n",
    "            system_to_paper.setdefault(system_id, []).append(paper_metadata)\n",
    "\n",
    "    # 2. System extrahieren\n",
    "    for system in ai_systems:\n",
    "        instance_data = {\n",
    "            \"id\": str(system).split(\"/\")[-1],\n",
    "            \"type\": \"System\",\n",
    "            \"metadata\": {},\n",
    "            \"relationships\": {},\n",
    "            \"documentation\": {},\n",
    "            \"papers\": [],\n",
    "            \"steps\": [],\n",
    "            \"variables\": {}\n",
    "        }\n",
    "\n",
    "        for pred, obj in g.predicate_objects(subject=system):\n",
    "            pred_name = pred.split(\"#\")[-1] if \"#\" in pred else pred.split(\"/\")[-1]\n",
    "            if isinstance(obj, URIRef):\n",
    "                instance_data[\"relationships\"].setdefault(pred_name, []).append(str(obj).split(\"/\")[-1])\n",
    "            else:\n",
    "                instance_data[\"metadata\"][pred_name] = str(obj)\n",
    "\n",
    "        # 3. Dokumentation extrahieren\n",
    "        if \"hasDocumentation\" in instance_data[\"relationships\"]:\n",
    "            for doc_id in instance_data[\"relationships\"][\"hasDocumentation\"]:\n",
    "                doc_uri = URIRef(f\"http://semantic-systems.net/swemls/{doc_id}\")\n",
    "                if (doc_uri, rdf_type, documentation_type) in g:\n",
    "                    instance_data[\"documentation\"][\"id\"] = doc_id\n",
    "                    for doc_pred, doc_obj in g.predicate_objects(subject=doc_uri):\n",
    "                        doc_pred_name = doc_pred.split(\"#\")[-1] if \"#\" in doc_pred else doc_pred.split(\"/\")[-1]\n",
    "                        instance_data[\"documentation\"][doc_pred_name] = str(doc_obj)\n",
    "\n",
    "        # 4. Paper hinzuf√ºgen\n",
    "        if selected_system_id in system_to_paper:\n",
    "            instance_data[\"papers\"] = system_to_paper[selected_system_id]\n",
    "\n",
    "        # 5. Schritte (ML/KR) extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for step_relation in [f\"hasStepML{i}\", f\"hasStepKR{i}\"]:\n",
    "                if step_relation in instance_data[\"relationships\"]:\n",
    "                    for step_id in instance_data[\"relationships\"][step_relation]:\n",
    "                        step_uri = URIRef(f\"http://semantic-systems.net/swemls/{step_id}\")\n",
    "                        step_type = \"Unknown\"\n",
    "                        if (step_uri, rdf_type, ml_component_type) in g:\n",
    "                            step_type = \"Machine Learning\"\n",
    "                        elif (step_uri, rdf_type, kr_component_type) in g:\n",
    "                            step_type = \"Knowledge Representation\"\n",
    "                        step_data = {\"id\": step_id, \"type\": step_type, \"metadata\": {}}\n",
    "                        for step_pred, step_obj in g.predicate_objects(subject=step_uri):\n",
    "                            step_pred_name = step_pred.split(\"#\")[-1] if \"#\" in step_pred else step_pred.split(\"/\")[-1]\n",
    "                            step_data[\"metadata\"].setdefault(step_pred_name, []).append(str(step_obj))\n",
    "                        instance_data[\"steps\"].append(step_data)\n",
    "\n",
    "        # 6. Variablen extrahieren\n",
    "        for i in range(1, 11):\n",
    "            for var_relation in [f\"hasVariableData{i}\", f\"hasVariableSW{i}\"]:\n",
    "                if var_relation in instance_data[\"relationships\"]:\n",
    "                    for var_id in instance_data[\"relationships\"][var_relation]:\n",
    "                        var_uri = URIRef(f\"http://semantic-systems.net/swemls/{var_id}\")\n",
    "                        label = None\n",
    "                        for _, _, label_value in g.triples((var_uri, rdfs_label, None)):\n",
    "                            label = str(label_value)\n",
    "                            break\n",
    "                        instance_data[\"variables\"][var_relation] = {\"id\": var_id, \"label\": label}\n",
    "\n",
    "        # 7. Speichern\n",
    "        json_filename = f\"{selected_system_id}.json\"\n",
    "        with open(json_filename, \"w\") as f:\n",
    "            json.dump(instance_data, f, indent=4)\n",
    "\n",
    "        with json_output:\n",
    "            json_output.clear_output()\n",
    "            print(f\"‚úÖ JSON successfully exported as: {json_filename}\")\n",
    "            print(json.dumps(instance_data, indent=2))  # Ausgabe f√ºr √úberpr√ºfung\n",
    "\n",
    "# === Button zum Starten der Extraktion ===\n",
    "extract_button = widgets.Button(description=\"Extract JSON\", button_style=\"success\")\n",
    "extract_button.on_click(lambda b: extract_and_export_selected_system())\n",
    "\n",
    "display(extract_button, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "pattern_output = widgets.Output()\n",
    "\n",
    "# === Funktion zur ID-Deduplizierung ===\n",
    "def deduplicate_ids(variables):\n",
    "    seen_ids = {}\n",
    "    updated_variables = {}\n",
    "\n",
    "    for key, var in variables.items():\n",
    "        original_id = var[\"id\"]\n",
    "        label = var.get(\"label\", \"\")\n",
    "\n",
    "        if original_id in seen_ids:\n",
    "            seen_ids[original_id] += 1\n",
    "            new_id = f\"{original_id}_{seen_ids[original_id]}\"\n",
    "        else:\n",
    "            seen_ids[original_id] = 1\n",
    "            new_id = original_id\n",
    "\n",
    "        updated_variables[key] = {\n",
    "            \"id\": new_id,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "    return updated_variables\n",
    "\n",
    "# === JSON-Datei einlesen und Variablen setzen ===\n",
    "def load_instance_json(json_filename):\n",
    "    global instance_data, pattern\n",
    "\n",
    "    try:\n",
    "        with open(json_filename, \"r\") as json_file:\n",
    "            extracted_data = json.load(json_file)\n",
    "            instance_data = extracted_data\n",
    "\n",
    "        # System-Label und Pattern-URI extrahieren\n",
    "        system_label = instance_data.get(\"metadata\", {}).get(\"label\", \"no label\")\n",
    "        raw_pattern_uri = instance_data.get(\"relationships\", {}).get(\"hasCorrespondingPattern\", [None])[0]\n",
    "\n",
    "        # Sicher extrahieren ‚Äì falls kein Pattern vorhanden, als \"no pattern\" setzen\n",
    "        if raw_pattern_uri:\n",
    "            pattern = raw_pattern_uri.split(\".\")[-1] if \"Pattern.\" in raw_pattern_uri else raw_pattern_uri.split(\"/\")[-1]\n",
    "        else:\n",
    "            pattern = \"no pattern\"\n",
    "\n",
    "        pattern_info = f\"üß© Pattern detected: {pattern}\" if pattern != \"no pattern\" else \"‚ö†Ô∏è No pattern detected\"\n",
    "\n",
    "        # IDs deduplizieren\n",
    "        instance_data[\"variables\"] = deduplicate_ids(instance_data.get(\"variables\", {}))\n",
    "\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚úÖ Loaded instance: {system_label}\")\n",
    "            print(f\"üìé raw_pattern_uri: {raw_pattern_uri}\")\n",
    "            print(f\"üß© pattern: {pattern}\")\n",
    "            print(pattern_info)\n",
    "\n",
    "        # Danach weitere Pattern-Entscheidung anzeigen\n",
    "        handle_pattern_selection()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚ùå Error loading JSON:\\n‚Üí {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå JSON file not found! Please extract an instance first.\")\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(f\"‚ùå Error loading JSON:\\n‚Üí {e}\")\n",
    "\n",
    "# === Button zur Ausf√ºhrung ===\n",
    "load_button = widgets.Button(description=\"Load Extracted JSON\", button_style=\"primary\")\n",
    "def on_load_click(b):\n",
    "    try:\n",
    "        json_file = f\"{selected_system_id}.json\"\n",
    "        load_instance_json(json_file)\n",
    "    except NameError:\n",
    "        with pattern_output:\n",
    "            pattern_output.clear_output()\n",
    "            print(\"‚ùå No system selected. Please extract a system first.\")\n",
    "\n",
    "load_button.on_click(on_load_click)\n",
    "\n",
    "\n",
    "display(load_button, pattern_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from rdflib import Graph, Namespace, RDF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# === Globals for reuse ===\n",
    "pattern_structure = None\n",
    "pattern_choice = None\n",
    "pattern_graph = None\n",
    "pattern = None\n",
    "\n",
    "# === Variables from previous steps assumed ===\n",
    "# instance_data (dict), pattern (str or \"no pattern\")\n",
    "\n",
    "# === Output containers ===\n",
    "pattern_output = widgets.Output()\n",
    "pattern_upload_output = widgets.Output()\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description=\"‚¨áÔ∏è Download Template XML\",\n",
    "    button_style=\"info\",\n",
    "    icon=\"download\"\n",
    ")\n",
    "download_output = widgets.Output()\n",
    "\n",
    "\n",
    "pattern_continue_button = widgets.Button(\n",
    "    description=\"Continue with uploaded pattern\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "# === Upload widget (only shown when needed) ===\n",
    "pattern_upload_widget = widgets.FileUpload(\n",
    "    accept='.ttl',\n",
    "    multiple=False,\n",
    "    description='Upload Pattern File'\n",
    ")\n",
    "\n",
    "# === Pattern decision: Template or Generate ===\n",
    "pattern_choice_selector = widgets.ToggleButtons(\n",
    "    options=[\n",
    "        (\"Use template\", \"template\"),\n",
    "        (\"Generate automatically\", \"generate\")\n",
    "    ],\n",
    "    description=\"Select Pattern Option:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def handle_pattern_selection():\n",
    "    global pattern, pattern_choice, pattern_structure\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "    pattern_upload_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        with pattern_output:\n",
    "            print(f\"üîç DEBUG pattern: {pattern}\")\n",
    "\n",
    "            if pattern is None or pattern == \"no pattern\":\n",
    "                print(\"üìÇ No pattern linked to system. Please upload a pattern TTL file.\")\n",
    "                display(pattern_upload_widget)\n",
    "                display(pattern_continue_button)  # ‚¨ÖÔ∏è Neuer Button wird angezeigt\n",
    "                display(pattern_upload_output)\n",
    "            else:\n",
    "                print(f\"üß© Pattern detected: {pattern}\")\n",
    "                print(\"How would you like to proceed?\")\n",
    "                display(pattern_choice_selector)\n",
    "    except Exception as e:\n",
    "        show_exception(e)\n",
    "        \n",
    "\n",
    "def on_pattern_continue(b):\n",
    "    global pattern_structure\n",
    "\n",
    "    with pattern_output:\n",
    "        pattern_output.clear_output()\n",
    "        print(\"üü¢ [DEBUG] Button clicked!\")\n",
    "\n",
    "        if not pattern_upload_widget.value:\n",
    "            print(\"üî¥ [DEBUG] No file in upload_widget.value\")\n",
    "            print(\"‚ö†Ô∏è No file uploaded. Please upload a pattern file first.\")\n",
    "            return\n",
    "\n",
    "        upload_items = list(pattern_upload_widget.value)\n",
    "        print(f\"üü° [DEBUG] Upload items found: {len(upload_items)}\")\n",
    "\n",
    "        if not upload_items:\n",
    "            print(\"‚ùå Upload seems empty.\")\n",
    "            return\n",
    "\n",
    "        upload_info = upload_items[0]\n",
    "        file_name = upload_info['name']\n",
    "        file_content = upload_info['content']\n",
    "\n",
    "        print(f\"üü¢ [DEBUG] File name = {file_name}\")\n",
    "        print(f\"üü¢ [DEBUG] File content size = {len(file_content)} bytes\")\n",
    "\n",
    "        try:\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                f.write(file_content)\n",
    "            print(\"üü¢ [DEBUG] File written to disk.\")\n",
    "\n",
    "            pattern_structure = extract_pattern_structure_from_file(file_name)\n",
    "            print(\"‚úÖ Pattern structure parsed:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading pattern file: {file_name}\")\n",
    "            print(str(e))\n",
    "\n",
    "# Am Ende registrieren:\n",
    "pattern_continue_button.on_click(on_pattern_continue)\n",
    "\n",
    "\n",
    "# === Extract logic from TTL file ===\n",
    "def extract_pattern_structure_from_file(file_path):\n",
    "    g = Graph()\n",
    "    g.parse(file_path, format=\"turtle\")\n",
    "\n",
    "    SWEMLS = Namespace(\"https://w3id.org/semsys/ns/swemls#\")\n",
    "    OPMW = Namespace(\"http://www.opmw.org/ontology/\")\n",
    "    RES = Namespace(\"http://semantic-systems.net/swemls/\")\n",
    "\n",
    "    def clean_uri(uri):\n",
    "        label = uri.split(\"/\")[-1].split(\"#\")[-1]\n",
    "        label = re.sub(r'Pattern\\.[A-Za-z0-9]+\\.', '', label)\n",
    "        label = re.sub(r'^[A-Za-z0-9]+\\.', '', label)\n",
    "        return label\n",
    "\n",
    "    structure = {\"steps\": {}, \"variables\": {}}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, SWEMLS.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessML):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"ML\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for step in g.subjects(RDF.type, RES.WorkflowTemplateProcessKR):\n",
    "        step_label = clean_uri(str(step))\n",
    "        inputs = [clean_uri(str(var)) for var in g.objects(step, OPMW[\"uses\"])]\n",
    "        structure[\"steps\"][step_label] = {\"type\": \"KR\", \"uses\": inputs, \"outputs\": []}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactData):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, SWEMLS.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    for var in g.subjects(RDF.type, RES.TemplateArtifactSW):\n",
    "        var_label = clean_uri(str(var))\n",
    "        generated_by = [clean_uri(str(gen)) for gen in g.objects(var, OPMW[\"isGeneratedBy\"])]\n",
    "        for gen in generated_by:\n",
    "            if gen in structure[\"steps\"]:\n",
    "                structure[\"steps\"][gen][\"outputs\"].append(var_label)\n",
    "        structure[\"variables\"][var_label] = {\"generated_by\": generated_by} if generated_by else {}\n",
    "\n",
    "    return structure\n",
    "\n",
    "# === Trigger on pattern upload ===\n",
    "def on_pattern_upload(change):\n",
    "    global pattern_structure\n",
    "\n",
    "    if not pattern_upload_widget.value:\n",
    "        return\n",
    "\n",
    "    uploaded = next(iter(pattern_upload_widget.value.items()))  # (filename, fileinfo)\n",
    "    file_name = uploaded[0]\n",
    "    file_content = uploaded[1]['content']\n",
    "\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(file_content)\n",
    "\n",
    "    with pattern_output:\n",
    "        clear_output()\n",
    "        print(f\"‚úÖ Pattern file uploaded: {file_name}\")\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_name)\n",
    "        with pattern_output:\n",
    "            print(\"‚úÖ Extracted pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"‚ùå Error parsing pattern file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pattern_upload_widget.observe(on_pattern_upload, names='value')\n",
    "\n",
    "\n",
    "\n",
    "def on_pattern_choice(change):\n",
    "    global pattern_choice, pattern_structure\n",
    "    pattern_choice = change['new']\n",
    "    file_path = f\"Patterns/{pattern}-pattern.ttl\"\n",
    "\n",
    "    pattern_output.clear_output()\n",
    "\n",
    "    try:\n",
    "        pattern_structure = extract_pattern_structure_from_file(file_path)\n",
    "\n",
    "        with pattern_output:\n",
    "            print(f\"‚úÖ Pattern '{pattern}' loaded from: {file_path}\")\n",
    "            print(f\"üß© Pattern mode selected: {pattern_choice}\")\n",
    "            print(\"üìä Pattern structure:\")\n",
    "            print(json.dumps(pattern_structure, indent=4))\n",
    "\n",
    "        # ‚¨ÖÔ∏è Hier Template erzeugen, wenn \"Use template\" gew√§hlt wurde\n",
    "        if pattern_choice == \"template\":\n",
    "            generate_template_from_instance()\n",
    "\n",
    "    except Exception as e:\n",
    "        with pattern_output:\n",
    "            print(f\"‚ùå Error reading pattern file: {file_path}\")\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "pattern_choice_selector.observe(on_pattern_choice, names='value')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "main_pattern_box = widgets.VBox([\n",
    "    pattern_output,\n",
    "    pattern_upload_output,\n",
    "    download_output  # üÜï Zeigt den Download-Link nach Template-Erstellung\n",
    "])\n",
    "\n",
    "\n",
    "# Button-Handler aktivieren ‚¨áÔ∏è\n",
    "pattern_continue_button.on_click(on_pattern_continue)\n",
    "\n",
    "# Danach Anzeige und Auswahl starten\n",
    "handle_pattern_selection()\n",
    "display(main_pattern_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# === Download-Ausgabe Widget ===\n",
    "download_output = widgets.Output()\n",
    "\n",
    "# === Alternative f√ºr Voila-kompatiblen Download ===\n",
    "from ipywidgets import FileDownload\n",
    "\n",
    "def extract_label_short(step):\n",
    "    labels = step.get(\"metadata\", {}).get(\"label\", [])\n",
    "    if labels:\n",
    "        match = re.search(r\"\\((.*?)\\)\", labels[0])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return step[\"id\"].split(\".\")[-1]\n",
    "\n",
    "def replace_pattern_placeholders(xml_string, instance_data, pattern_structure):\n",
    "    tree = ET.ElementTree(ET.fromstring(xml_string))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    replacements = {}\n",
    "\n",
    "    # üîÅ Steps (ML/KR)\n",
    "    for step in instance_data.get(\"steps\", []):\n",
    "        step_key = step[\"id\"].split(\".\")[-1]\n",
    "        step_label = extract_label_short(step)\n",
    "        replacements[step_key] = step_label\n",
    "\n",
    "    # üîÅ Variables\n",
    "    for pattern_var in pattern_structure.get(\"variables\", {}):\n",
    "        for var_key, var_data in instance_data.get(\"variables\", {}).items():\n",
    "            if pattern_var.lower() in var_key.lower():\n",
    "                inst_id = var_data[\"id\"].replace(\"Resource.\", \"\").replace(\"Custom.\", \"\")\n",
    "                replacements[pattern_var] = inst_id\n",
    "                break\n",
    "\n",
    "    print(\"\\nüß© Mapping for replacements:\")\n",
    "    for k, v in replacements.items():\n",
    "        print(f\"  {k} ‚Üí {v}\")\n",
    "\n",
    "    for element in root.iter(\"mxCell\"):\n",
    "        if 'value' in element.attrib:\n",
    "            value = element.attrib['value']\n",
    "            for placeholder, real_value in replacements.items():\n",
    "                if placeholder in value:\n",
    "                    replacement = real_value.replace(\"_\", \" \") if real_value.strip() else \"Missing\"\n",
    "                    style = element.attrib.get(\"style\", \"\")\n",
    "                    length = len(replacement)\n",
    "                    if length > 24:\n",
    "                        style += \";fontSize=5\"\n",
    "                    elif length > 20:\n",
    "                        style += \";fontSize=7\"\n",
    "                    elif length > 17:\n",
    "                        style += \";fontSize=9\"\n",
    "                    element.attrib['style'] = style\n",
    "                    element.attrib['value'] = value.replace(placeholder, replacement)\n",
    "\n",
    "    return ET.tostring(root, encoding='utf8', method='xml').decode()\n",
    "\n",
    "def generate_template_from_instance():\n",
    "    global pattern, instance_data, pattern_structure\n",
    "\n",
    "    if not pattern or pattern in (\"no pattern\", \"None\", None):\n",
    "        print(\"‚ö†Ô∏è Kein g√ºltiges Pattern gesetzt. Abbruch.\")\n",
    "        return\n",
    "\n",
    "    template_path = f\"Templates/{pattern}.xml\"\n",
    "\n",
    "    if not os.path.exists(template_path):\n",
    "        print(f\"‚ùå Template-Datei nicht gefunden: {template_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            xml_template = f.read()\n",
    "\n",
    "        updated_xml = replace_pattern_placeholders(xml_template, instance_data, pattern_structure)\n",
    "\n",
    "        output_path = f\"Updated_{pattern}_Workflow.xml\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(updated_xml)\n",
    "\n",
    "        print(f\"‚úÖ Template erfolgreich generiert: {output_path}\")\n",
    "\n",
    "        # üíæ Download-Widget f√ºr Voila-kompatiblen Download anzeigen\n",
    "        with download_output:\n",
    "            download_output.clear_output()\n",
    "            file_dl = FileDownload(data=updated_xml, filename=output_path, description=\"‚¨áÔ∏è Download XML\", button_style=\"success\")\n",
    "            display(file_dl)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler beim Generieren des Templates: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
